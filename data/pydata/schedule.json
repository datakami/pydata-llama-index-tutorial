{"schedule": {"version": "0.8", "base_url": "https://amsterdam2023.pydata.org/cfp/schedule/", "conference": {"acronym": "cfp", "title": "PyData Amsterdam 2023", "start": "2023-09-14", "end": "2023-09-16", "daysCount": 3, "timeslot_duration": "00:05", "time_zone_name": "Europe/Amsterdam", "rooms": [{"name": "Room 1", "guid": null, "description": null, "capacity": null}, {"name": "Room 2", "guid": null, "description": null, "capacity": null}, {"name": "[Deprecated] Room 3", "guid": null, "description": "There was an odd issue with the availability settings of this room; can be discarded", "capacity": null}, {"name": "Room 3", "guid": null, "description": null, "capacity": null}, {"name": "Tutorial Room", "guid": null, "description": null, "capacity": null}], "days": [{"index": 1, "date": "2023-09-14", "day_start": "2023-09-14T04:00:00+02:00", "day_end": "2023-09-15T03:59:00+02:00", "rooms": {"Room 1": [{"id": 58, "guid": "0028b7eb-2e98-56ec-9fed-e4cd83f4d118", "logo": "", "date": "2023-09-14T10:30:00+02:00", "start": "10:30", "duration": "00:30", "room": "Room 1", "slug": "cfp-58-forecasting-customer-lifetime-value-cltv-for-marketing-campaigns-under-uncertainty-with-pystan", "url": "https://amsterdam2023.pydata.org/cfp/talk/EE8XKQ/", "title": "Forecasting Customer Lifetime Value (CLTV) for Marketing Campaigns under Uncertainty with PySTAN", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In this talk, we discuss how we can use the python package PySTAN to estimate the Lifetime Value (LTV) of the users that can be acquired from a marketing campaign, and use this estimate to find the optimal bidding strategy when the LTV estimate itself has uncertainty. Throughout the presentation, we highlight the benefits from using Bayesian modeling to estimate LTV, and the potential pitfalls when forecasting LTV. By the end of the presentation, attendees will have a solid understanding of how to use PySTAN to estimate LTV,  optimize their marketing campaign bidding strategies, and implement the best Bayesian modelling solution. All of the contents and numbers in this presentation can be found in the shared GIT", "description": "We describe how to use the PySTAN to forecast the LTV of the marketing campaigns. PySTAN is a Python interface to STAN, which is a package for Bayesian inference capable of high-performance statistical computation. PySTAN\u2019s computation speed is essential in a marketing context, where we need to predict the LTV of multiple marketing campaigns over a long period, while still estimating the LTV distribution. We demonstrate how to implement a PySTAN model to predict a time-series using the Lifetime Value data from Kaggle [2], which contains approximately 200 days, in less than 2 minutes. While this is long compared to point-estimate algorithms, it is still much faster than a similar code using PyMC, another probabilistic programming library.\r\n\r\nWith the LTV accurately predicted for the Lifetime Value data, we explain the steps to optimize the bid of marketing campaigns under uncertainty about the accuracy of our predictions. We show how different levels of uncertainty of our LTV predictions can change the optimal bidding strategy and answer questions such as \u201cHow much should we underbid when we are unsure of our LTV?\u201d.\r\nBy the end of the presentation, attendees will be able to implement PySTAN to estimate LTV and apply this knowledge to find the best bidding strategy for their marketing campaigns.\r\n\r\nIn this presentation, we will thus cover the following topics:\r\n- [3 min] What is PyMC\r\n- [5 min] Modeling advertisement for digital products\r\n- [10 min] How to use PySTAN to estimate the LTV of your marketing campaigns\r\n- [10 min] How to achieve the same model through PyMC\r\n- [2 min] How PyMC compares to those alternatives in terms of implementation ease, execution speed, and support for further improvements\r\n[5 min] How to find the optimal bid for your marketing campaign\r\n[5 min] How the optimal bid for a marketing campaign varies under different levels of uncertainty of its LTV and elasticity (i.e. how many more users we get by increasing the spend in the marketing campaign)\r\n\r\n\r\n**References**\r\n- The Duopoly is over because everything is an ad network[ [https://mobiledevmemo.com/the-duopoly-is-over-because-everything-is-an-ad-network/]\r\n- Lifetime Value data from Kaggle: https://www.kaggle.com/datasets/baetulo/lifetime-value?select=train.csv", "recording_license": "", "do_not_record": false, "persons": [{"id": 72, "code": "39LSSC", "public_name": "Raphael de Brito Tamaki", "biography": "I'm a data scientist working in Meta in the Marketing Science department, and previously worked in Wildlife Studios, a mobile game studio where I led the Lifetime Value prediction team. While I'm mostly pragmatic and opt for boring solutions and libraries, I have particular interest in probabilistic libraries and programming languages and causal inference.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 135, "guid": "0b21795f-fb6f-583d-a77d-bceee45fd768", "logo": "", "date": "2023-09-14T11:20:00+02:00", "start": "11:20", "duration": "00:30", "room": "Room 1", "slug": "cfp-135-causal-inference-libraries-what-they-do-what-i-d-like-them-to-do", "url": "https://amsterdam2023.pydata.org/cfp/talk/877P7Y/", "title": "Causal Inference Libraries: What They Do, What I'd Like Them To Do", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk will explore the Python tooling and ecosystem for estimating conditional average treatment effects (CATEs) in a Causal Inference setting. Using real world-examples, it will compare and contrast the pros and cons of various existing libraries as well as outline desirable functionalities not currently offered by any public library.", "description": "Conditional average treatment effects (CATEs) are a fundamental concept in Causal Inference, allowing for the estimation of the effect of a particular treatment or intervention. For CATEs, the effect estimation is not only with respect to an entire population, e.g. all experiment participants, but rather with respect to units, e.g. a single experiment participant, with individual characteristics. This can be very important to meaningfully personalize services and products. In this talk, we will explore the Python tooling and ecosystem for estimating CATEs, including libraries such as EconML and CausalML.\r\n\r\nWe will begin by providing an overview of the theory behind CATE estimation, how it fits into the broader field of causal inference and how Machine Learning has recently broken into CATE estimation. We will then dive into the various libraries available for Python, discussing their strengths and weaknesses and providing real-world examples of their usage.\r\n\r\nSpecifically, we will cover:\r\n- EconML: An open-source library for general Causal Inference purposes, by Microsoft Research\r\n- CausalML: An open-source library for uplift modeling in particular, by Uber\r\n\r\nWe will compare and contrast these libraries with respect to CATE estimation, discussing which methods they use, which assumptions they make, and which types of data they are best suited for. We will also provide code examples to illustrate how to use each library in practice. Moreover, we will discuss what we think is missing from both of them.\r\n\r\nBy the end of the talk, attendees will have a solid understanding of the Python tooling and ecosystem for estimating CATEs in a causal inference setting. They will know which libraries to use for different types of data and which methods are most appropriate for different scenarios.\r\n\r\nThis talk could be particularly relevant for Data Scientists wishing to analyze experiments, such as A/B tests, or trying to derive causal statements from observational, non-experimental data. Participants are not expected to have Causal Inference expertise. Yet, a fundamental understanding of Machine Learning and Probability Theory will be beneficial.\r\n\r\n0-5\u2019: Why Causal Inference and why CATE estimation?\r\n5-10\u2019: What are some conceptual ways of estimating CATEs?\r\n10-20\u2019: How can we use EconML and CausalML for CATE estimation on a real dataset?\r\n20-30\u2019: What are we missing from EconML and CausalML?", "recording_license": "", "do_not_record": false, "persons": [{"id": 32, "code": "L8XFRK", "public_name": "Kevin Klein", "biography": "Kevin is a Data Scientist at QuantCo, working on fraud detection, risk modelling and experimentation. Prior to joining QuantCo, he focused on Natural Language Processing, discrete optimization and Bayesian optimization during his Computer Science major at ETH, Zurich. \r\nHe's not very original in that he likes functional programming, running and writing.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 40, "guid": "7b6015d4-f08c-5df1-a904-965815a3180b", "logo": "", "date": "2023-09-14T12:00:00+02:00", "start": "12:00", "duration": "00:30", "room": "Room 1", "slug": "cfp-40-staggered-difference-in-differences-in-practice-causal-insights-from-the-music-industry", "url": "https://amsterdam2023.pydata.org/cfp/talk/GYV8FE/", "title": "Staggered Difference-in-Differences in Practice: Causal Insights from the Music Industry", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "The Difference-in-Differences (DiD) methodology is a popular causal inference method utilized by leading tech firms such as Microsoft Research, LinkedIn, Meta, and Uber. Yet recent studies suggest that traditional DiD methods may have significant limitations when treatment timings differ. An effective alternative is the implementation of the staggered DiD design. We exemplify this by investigating an interesting question in the music industry: Does featuring a song in TV shows influence its popularity, and are there specific factors that could moderate this impact?", "description": "Difference-in-differences (DiD) is a causal inference method frequently used in empirical research in industry and academia. However, standard DiD has limitations when interventions occur at different times or affect varying groups. This talk will highlight the application of the Staggered DiD method, a more nuanced approach that addresses these limitations, in the context of the music industry. We will try to answer the question of how music features in TV shows affect music popularity and how this effect might change for different types of music using the staggered DiD method. Attendees will gain an understanding of causal inference through observational studies and specifically how the new DiD methods are used through an interesting and original case study.\r\n\r\n\r\nThe talk will be structured as follows:\r\n\r\n1. Intro to the case (e.g., background on music features on TV, dataset) (5 mins)\r\n2. Explanation of the DiD approach and its limitations. (5 mins)\r\n3.  Introduction to the Staggered DiD method. (5 mins)\r\n4. Application of staggered DiD for the case study from the music industry (10 mins)\r\n5.  Conclusions (5 mins)\r\n\r\nTarget Audience: The talk would be beneficial for data scientists, researchers, and practitioners interested in causal inference, marketing analytics, and quasi-experimental design. Attendees should have a basic understanding of statistical methods used in data science.\r\n\r\nKey Takeaways:\r\n\r\n1.  Understanding of the DiD approach and its limitations in the context of analyses with observational data.\r\n2.  Insights into the Staggered DiD method and its application.\r\n3.  Practical knowledge about executing and evaluating DiD studies effectively.", "recording_license": "", "do_not_record": false, "persons": [{"id": 52, "code": "QDBVRK", "public_name": "Nazli M. Alagoz", "biography": "I am a quantitative researcher and data scientist with a strong background in marketing, economics, and econometrics. My focus is on using data-driven approaches to tackle complex business challenges, uncover valuable insights, and drive impactful decisions. As a Ph.D. candidate in quantitative marketing, I specialize in causal inference, machine learning, and experimental design to address cutting-edge research questions.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 258, "guid": "64283b01-5050-5b2a-bfa7-67044ee6b343", "logo": "", "date": "2023-09-14T13:30:00+02:00", "start": "13:30", "duration": "00:30", "room": "Room 1", "slug": "cfp-258-don-t-judge-a-book-by-its-cover-using-llm-created-datasets-to-train-models-that-detect-literary-features", "url": "https://amsterdam2023.pydata.org/cfp/talk/8KPKN8/", "title": "Don\u2019t judge a book by its cover: Using LLM created datasets to train models that detect literary features", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Existing book recommendation systems like Goodreads are based on correlating the reading habits of people. But what if you want a humorous book? Or a book that is set in 19th century Paris? Or a thriller, but without violence? \r\nWe build book recommendation systems for Dutch libraries based on more than a dozen features from historical setting, to writing style, to main character characteristics. This allows us to tailor each recommendation to individual readers.", "description": "The recent developments in LLMs are an interesting area for us to explore to improve our recommendations. However, running LLMs in production is unfortunately not always feasible. The associated costs may be too high, and running code from third parties in your daily pipeline may be undesirable. And then there\u2019s data privacy -  or, in our case, intellectual copyright - to be considered as well. \r\n\r\nSo how can you reap the benefits of an LLM, without exposing yourself or your company to some of these major downsides? \r\n\r\nWe utilized LLMs to generate custom, tailor-made datasets for our literary feature detection models to train on. This allowed us to benefit from the high performance of large language models, without continued reliance on external parties such as OpenAI or Google.\r\n\r\nWhile you may think LLMs are not as effective for languages other than English, we\u2019ve seen major improvements in several of our models. \r\n\r\nIn this talk, we\u2019ll highlight:\r\n- A note on recommenders: Why does Goodreads recommender not work for me, while Spotify\u2019s Discover Weekly is so good?\r\n- Different methods of getting data from books\r\n- Iterative process of creating a dataset using an LLM and retraining our models\r\n- Some notes on intellectual property and evaluation of models.", "recording_license": "", "do_not_record": false, "persons": [{"id": 248, "code": "AWFV3Y", "public_name": "Wessel Sandtke", "biography": "Typewriter repairman turned Machine Learning Engineer, now working for Bookarang, a Dutch startup working with Dutch libraries to improve the recommendations for its members.\r\nWrote several picture books, but is not allowed to boost those in the recommendation system.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 192, "guid": "df2190cb-ce2b-5155-bf89-47ef2a5a8594", "logo": "", "date": "2023-09-14T14:10:00+02:00", "start": "14:10", "duration": "00:30", "room": "Room 1", "slug": "cfp-192-mind-the-language-how-to-monitor-nlp-and-llm-in-production", "url": "https://amsterdam2023.pydata.org/cfp/talk/ZMHSU9/", "title": "Mind the language: how to monitor NLP and LLM in production", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "How can you evaluate your production models when the data is not structured and you have no labels? To start, by tracking patterns and changes in the input data and model outputs. In this talk, I will give an overview of the possible approaches to monitor NLP and LLM models: from embedding drift detection to using regular expressions.", "description": "Once LLMs or NLP models are in production, you want to ensure they work as intended. But how can you observe their behavior in the wild and detect when something goes wrong?\r\n\r\nFirst, you often lack true labels. To add to this, the data is unstructured - how exactly can you track a pile of texts? \r\n\r\nMonitoring the patterns in the input data and model outputs is often the first line of defense. In the talk, I will review possible approaches to monitoring drift and data quality issues in text data and explain their pros and cons. \r\n\r\nI will cover:\r\n- Statistical embedding drift detection  \r\n- Tracking interpretable text descriptors like text length and sentiment\r\n- Using regular expressions to validate outputs\r\n- Explaining drift through model-based drift detection\r\n- Detecting changes in multi-modal data\r\n\r\nI will also introduce open-source tools, models, and visualization techniques one can use to monitor LLM and NLP models. \r\n\r\nThis talk will benefit data scientists and machine learning engineers who work with NLP and LLM in production.", "recording_license": "", "do_not_record": false, "persons": [{"id": 195, "code": "KVX3AC", "public_name": "Emeli Dral", "biography": "Emeli Dral is a Co-founder and CTO at Evidently AI, a startup developing open-source tools to evaluate, test, and monitor the performance of machine learning models.\r\n\r\nEarlier, she co-founded an industrial AI startup and served as the Chief Data Scientist at Yandex Data Factory. She led over 50 applied ML projects for various industries - from banking to manufacturing. Emeli is a data science lecturer at GSOM SpBU and Harbour.Space University. She is a co-author of the Machine Learning and Data Analysis curriculum at Coursera with over 100,000 students.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 191, "guid": "7097b087-3738-56ca-b572-6026df468b73", "logo": "", "date": "2023-09-14T15:10:00+02:00", "start": "15:10", "duration": "00:30", "room": "Room 1", "slug": "cfp-191-revealing-the-true-motives-of-news-readers", "url": "https://amsterdam2023.pydata.org/cfp/talk/8PWH9X/", "title": "Revealing the True Motives of News Readers", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Every news consumer has needs and in order to build a true bond with your customer it is vital to meet these, sometimes, diverse needs. To achieve this, first of all, it is important to identify the overarching needs of users; the reason why they read news. The BBC conducted research to determine these needs and identified six distinct categories: Update me, Keep me on trend, Give me perspective, Educate me, Divert me, and Inspire me. Their research showed that an equal distribution of content across these user needs will lead to higher customer engagement and loyalty. To apply this concept within DPG Media, we started building our own user needs model. Through various iterations of text labelling, text preparation, model building, fine-tuning and evaluation, we have arrived at a BERT model that is capable of determining the associated user needs based solely on the article text.", "description": "We would like to take the audience through all the steps that we have taken to get to the point where we are right now. During this process we had to find solutions to many obstacles and we are happy to share these lessons with the audience. Furthermore, we want to discuss all the tools and techniques that we used in order to arrive at the current phase. \r\n\r\nThe focus of the talk is on preparing the datasets and building the models, so a background in data science, engineering and/or machine learning is usefull. \r\n\r\nThe time breakdown will be the following:\r\nMinutes 0-5: introducing the topic and explaining why it is important\r\nMinutes 5-10: discussing the tools that we used and prior decisions we made\r\nMinutes 10-20: going through the labelling process and different models we build\r\nMinutes 20-25: sharing results and lessons learnt\r\nMinutes 25-30: giving insights into next steps and future applications", "recording_license": "", "do_not_record": false, "persons": [{"id": 199, "code": "NNRANL", "public_name": "Jurriaan Nagelkerke", "biography": "Data Scientist with 15+ years experience in getting value out of data for various companies in different branches. Love to apply the right ML/ AI techniques to answer business questions and actually make a difference. Aside from hands on consultant i'm also trainer in various ML techniques. Last few years strong focus on textual data / NLP and transformer models / LLMs.", "answers": []}, {"id": 205, "code": "TQWFFU", "public_name": "Vincent Smeets", "biography": "Hi, my name is Vincent Smeets. I am one of the data scientists within the Data And Customer Analytics department at DPG Media. I am responsible for generating insights from structured and semi-structured data to support decision making within the B2C Marketing organisation. In my freetime I love skateboarding, tennis and running.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 2": [{"id": 101, "guid": "e5266795-c955-5045-bfbe-9b7206a3da31", "logo": "", "date": "2023-09-14T10:30:00+02:00", "start": "10:30", "duration": "00:30", "room": "Room 2", "slug": "cfp-101-extend-your-scikit-learn-workflow-with-hugging-face-and-skorch", "url": "https://amsterdam2023.pydata.org/cfp/talk/PDPULJ/", "title": "Extend your scikit-learn workflow with Hugging Face and skorch", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Discover how to bridge the gap between traditional machine learning and the rapidly evolving world of AI with skorch. This package integrates the Hugging Face ecosystem while adhering to the familiar scikit-learn API. We will explore fine-turing of pre-trained models, creating our own tokenizers, accelerating model training, and leveraging Large Language Models.", "description": "The machine learning world is evolving quickly, AI is talked about everywhere, with the Hugging Face ecosystem being in the midst of it. For traditional machine learning users, especially coming from scikit-learn, keeping up can be quite overwhelming. With the help of the skorch package, it is possible to marry the best of both worlds. It allows you to integrate with many of the Hugging Face features while conforming to the sklearn API.\r\n\r\nIn this talk, I'll give a brief introduction to skorch. Then we will learn how to use it to tap into the Hugging Face ecosystem, benefiting from: using pre-trained models and fine-tuning them, working with tokenizers as if they were sklearn transformers, accelerating model training, and even using Large Language Models as zero-shot classifiers. I'll discuss some benefits and drawbacks of this approach.\r\n\r\nThis talk should be of interest to you if you're coming from the scikit-learn world and are interested in the latest deep learning developments. Familiarity with scikit-learn and a little bit of PyTorch knowledge is recommended.", "recording_license": "", "do_not_record": false, "persons": [{"id": 120, "code": "TCXN9E", "public_name": "Benjamin Bossan", "biography": "I worked as a Data Scientist and Head of Data Science for a couple of ears, now I'm Machine Learning Engineer at Hugging Face. I'm also a maintainer of the skorch package (https://github.com/skorch-dev/skorch).", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 231, "guid": "32b0fc9d-f825-59d5-87bf-1865861452e6", "logo": "", "date": "2023-09-14T11:20:00+02:00", "start": "11:20", "duration": "00:30", "room": "Room 2", "slug": "cfp-231-from-vision-to-action-designing-and-deploying-effective-computer-vision-pipelines", "url": "https://amsterdam2023.pydata.org/cfp/talk/Q3PUHA/", "title": "From Vision to Action: Designing and Deploying Effective Computer Vision Pipelines", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In the world of computer vision, the focus is often on cutting-edge neural network architectures. However, the true impact usually lies in designing a robust system around the model to solve real-world business challenges. In this talk, we guide you through the process of building practical computer vision pipelines that leverage techniques such as segmentation, classification, and object tracking, demonstrated by our predictive maintenance application at Port of Rotterdam. Whether you're an experienced expert seeking production-worthy pipelines or a novice with a background in data science or engineering eager to dive into image and video processing, we will explore the use of open-source tools to develop and deploy computer vision applications.", "description": "This talk provides a comprehensive demonstration of creating a powerful computer vision pipeline using widely-used libraries such as PyTorch, torchvision, and OpenCV. We break the pipeline down into manageable components, discussing the importance of proper separation of concerns. Onboarding new use cases becomes a breeze when following best practices in the project structure, combined with user-friendly command-line interfaces. Efficient development and validation processes are ensured by designing a sane data model and writing useful tests. Additionally, we explore the critical topic of maintainability, applying MLOps principles for long-term success.\r\n\r\nTo bring these concepts to life, we present a real-world application: the Machine Learning Inspector. This predictive maintenance tool, deployed at the Port of Rotterdam, automatically detects and inspects objects in video streams from trucks and ships, delivering actionable insights. We discuss how we work together with asset inspectors to capture their knowledge of the real world in our artificially intelligent computer vision tool.\r\n\r\nJoin us in this talk to gain practical knowledge and valuable insights for designing, deploying, and maintaining computer vision pipelines that drive tangible impact. We aim to empower the audience to build their own computer vision pipelines; with the right design philosophy, every data professional should be able to build computer vision pipelines that might be complex, but not complicated.", "recording_license": "", "do_not_record": false, "persons": [{"id": 230, "code": "KWCWJM", "public_name": "Wesley Boelrijk", "biography": "Machine Learning Engineer", "answers": []}, {"id": 251, "code": "H3HFPQ", "public_name": "Jeroen", "biography": "Machine learning engineer", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 28, "guid": "80309313-5f6a-58dd-b81f-730483b2dd6b", "logo": "", "date": "2023-09-14T12:00:00+02:00", "start": "12:00", "duration": "00:30", "room": "Room 2", "slug": "cfp-28-online-ml-serving-best-practices", "url": "https://amsterdam2023.pydata.org/cfp/talk/NSZFRB/", "title": "Online ML Serving best practices", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Working on ML serving for couple of years we learned a lot. I would like to share a set of best practices / learnings with the community", "description": "At Adyen we deploy a lot of models for online inference in the payment flow. Working in the MLOps team to streamline this process, I learned a lot about best practices / things to consider before (after) putting a model online. These are small things but they do contribute to a production and reliable setup for online inference. Some examples:\r\n\r\n- Adding meta data & creating a self contained archive\r\n- Separating serving sources from training sources\r\n- Choosing the requirements of model\r\n- Adding an example input & output request\r\n- Adding schemas for input and output\r\n- Common issues when putting models online: memory leaks, concurrency\r\n- Which server is best? Process based or thread based\r\n- How different python versions affect inference (execution) time", "recording_license": "", "do_not_record": false, "persons": [{"id": 42, "code": "RBKUVL", "public_name": "Ziad Al Moubayed", "biography": "Staff Engineer @ Adyen. I am passionate about high performance distributed systems. Recently I was working on scaling Adyen's Data & ML infrastructure.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 67, "guid": "e5441b76-3ff7-596b-9e16-45abb13d0a77", "logo": "", "date": "2023-09-14T13:30:00+02:00", "start": "13:30", "duration": "00:30", "room": "Room 2", "slug": "cfp-67-in-process-analytical-data-management-with-duckdb", "url": "https://amsterdam2023.pydata.org/cfp/talk/U93EST/", "title": "In-Process Analytical Data Management with DuckDB", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "DuckDB is a novel analytical data management system. DuckDB supports complex queries, has no external dependencies, and is deeply integrated into the Python ecosystem. Because DuckDB runs in the same process, no serialization or socket communication has to occur, making data transfer virtually instantaneous. For example, DuckDB can directly query Pandas data frames faster than Pandas itself. In our talk, we will describe the user values of DuckDB, and how it can be used to improve their day-to-day lives through automatic parallelization, efficient operators and out-of-core operations.", "description": "Data management systems and data analysts have a troubled relationship: Common systems such as Postgres or Spark are unwieldy, hard to set up and maintain, hard to transfer data in and out, and hard to integrate into complex end-to-end workflows. As a response, analysts have developed their own ecosystem of data wrangling tools such as Pandas or Polars. These tools are much more natural for analysts to use, but are limited in the amount of data they can process or the amount of automatic optimization that is supported. \r\n\r\nDuckDB is a new analytical data management system that is built for an in-process use case. DuckDB speaks SQL, has no external dependencies, and is deeply integrated into the Python ecosystem. DuckDB is Free and Open Source software under the MIT license. DuckDB uses state-of-the art query processing techniques with vectorized execution, lightweight compression, and morsel-driven automatic parallelism. DuckDB is out-of-core capable, meaning that it is capable of not only reading datasets that are bigger than main memory. This allows for analysis of far greater datasets and in many cases removes the need to run separate infrastructure. \r\n\r\nThe \u201cduckdb\u201d Python package is not a client to the DuckDB system, it provides the entire database engine. DuckDB runs without any external server directly inside the Python process. Once there, DuckDB can run complex SQL queries on data frames in Pandas, Polars or PyArrow formats out-of-the box. DuckDB can also directly ingest files in Parquet, CSV or JSON formats. Because DuckDB runs in the same process, data transfer are virtually instantaneous. Conversely, DuckDB\u2019s query results can be transferred back into data frames very cheaply, allowing direct integration with complex downstream libraries such as PyTorch or TensorFlow. \r\n\r\nDuckDB enjoys fast-growing popularity, the Python package alone is currently downloaded around one million times a month. DuckDB has recently become the default backend of the Ibis project that offers a consistent interface in Python over a variety of data backends. \r\n\r\nThis talk is aimed at two main groups, data analysts and data engineers. For the analysts, we will explain the user values of DuckDB, and how it can be used to improve their day-to-day lives. For data engineers, we will describe DuckDB\u2019s capabilities to become part of large automated data pipelines. The presenters for the proposed talk, Hannes M\u00fchleisen and Mark Raasveldt are the original creators of DuckDB, they are still leading the project and are deeply familiar with its Python integration.\r\n\r\n- DuckDB Python API Overview: https://duckdb.org/docs/api/python/overview\r\n- DuckDB PyPI Download Statistics: https://pypistats.org/packages/duckdb\r\n- DuckDB Ibis Backend: https://ibis-project.org/backends/DuckDB/\r\n- Peer-reviewed paper about the concept behind DuckDB by the presenters\r\nhttps://www.cidrdb.org/cidr2020/papers/p23-raasveldt-cidr20.pdf\r\n- Talk about DuckDB at FOSDEM 2020 by Hannes: https://archive.fosdem.org/2020/schedule/event/duckdb/\r\n- Talk about DuckDB at CMU by Mark:\r\nhttps://www.youtube.com/watch?v=PFUZlNQIndo", "recording_license": "", "do_not_record": false, "persons": [{"id": 84, "code": "9U8RFV", "public_name": "Hannes M\u00fchleisen", "biography": "Prof. Dr. Hannes M\u00fchleisen is a creator of the DuckDB database management system and Co-founder and CEO of DuckDB Labs, a consulting company providing services around DuckDB. He is also a senior researcher of the Database Architectures group at the Centrum Wiskunde & Informatica (CWI), the Dutch national research lab for Mathematics and Computer Science in Amsterdam. Hannes is also Professor of Data Engineering at Radboud Universiteit Nijmegen. His' main interest is analytical data management systems.", "answers": []}, {"id": 85, "code": "S8A8YL", "public_name": "Mark Raasveldt", "biography": "CTO at DuckDB Labs", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 92, "guid": "c450cf56-9c5f-5fa4-8e9d-d05c0a5af981", "logo": "/media/cfp/submissions/E38J9M/cover_zknOWTC.png", "date": "2023-09-14T14:10:00+02:00", "start": "14:10", "duration": "00:30", "room": "Room 2", "slug": "cfp-92-declarative-data-manipulation-pipeline-with-dagster", "url": "https://amsterdam2023.pydata.org/cfp/talk/E38J9M/", "title": "Declarative data manipulation pipeline with Dagster", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Bored of old pipeline orchestrator? Difficult to understand if data is up-to-date? Trouble with development workflow of data pipeline?\r\nDagster, an open-source tool, offers a unique paradigm that simplifies the orchestration and management of data pipelines.\r\nBy adopting declarative principles, data engineers and data scientists can build scalable, maintainable, and reliable pipelines effortlessly. \r\nWe will commence with an introduction to Dagster, covering its fundamental concepts to ensure a comprehensive understanding of the material.\r\nSubsequently, we will explore practical scenarios and use cases, with also DBT for empower the power of SQL language.\r\n\r\nMinutes 0-5: Explain the design pattern problem of actual data pipeline framework.\r\nMinutes 5-15: Introduction to Dagster and its core concepts.\r\nMinutes 10-25: Practical examples of building declarative data pipelines with Dagster, with also DBT, the power of gRPC server.\r\nMinutes 25-30: Q&A and conclusion.", "description": "Are you tired of struggling with outdated pipeline orchestrators? Do you find it challenging to ensure your data is always up-to-date? Are you facing difficulties with the development workflow of your data pipeline?\r\n\r\nIn this session, we will introduce Dagster, an open-source tool that revolutionizes the orchestration and management of data pipelines. By embracing declarative principles, data engineers and data scientists can effortlessly build scalable, maintainable, and reliable pipelines.\r\n\r\nWe will begin by providing an overview of the design pattern problem that many existing data pipeline frameworks face. Understanding the limitations of these frameworks will set the stage for exploring the transformative capabilities of Dagster\r\n\r\nNext, we will delve into the core concepts of Dagster, ensuring a comprehensive understanding of the material. You will learn how Dagster simplifies pipeline development and execution by providing a declarative and intuitive approach. Through practical examples and hands-on demonstrations, we will showcase how you can leverage Dagster to build powerful data pipelines.\r\n\r\nBut that's not all! We will also explore the integration of DBT, empowering you to harness the full potential of the SQL language within your data pipelines. You will witness the synergy between Dagster and DBT, unlocking new possibilities for data manipulation and transformation.\r\n\r\nBy the end, you'll be equipped with the knowledge and inspiration to elevate your data pipeline workflows to new heights.\r\n\r\nOutline:\r\n\r\nMinutes 0-5: Understanding the design pattern problem of existing data pipeline frameworks\r\nMinutes 5-15: Introduction to Dagster and its core concepts\r\nMinutes 10-25: Practical examples of building declarative data pipelines with Dagster, including the integration with DBT and the power of gRPC server\r\nMinutes 25-30: Q&A and conclusion", "recording_license": "", "do_not_record": false, "persons": [{"id": 112, "code": "ZVTR7U", "public_name": "Riccardo Amadio", "biography": "Senior Data Engineer at Agile Lab with a background of Data Scientist and Software Engineer. \r\nWhen I don't work with data pipelines , I juggle between closing some of my 100+ open tabs on the browser and my true passion: collecting stars on GitHub \ud83d\udd2d\ud83c\udf1f. In this treasure trove of more than 2,000 repositories, I am pretty sure I can find any tool to solve a problem, and I can\u2019t wait to share them with you.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 68, "guid": "e9d34ab2-6fdf-5b41-82c0-2365a11d012e", "logo": "", "date": "2023-09-14T15:10:00+02:00", "start": "15:10", "duration": "00:30", "room": "Room 2", "slug": "cfp-68-pyiceberg-tipping-your-toes-into-the-petabyte-data-lake", "url": "https://amsterdam2023.pydata.org/cfp/talk/TKYDMQ/", "title": "PyIceberg: Tipping your toes into the petabyte data-lake", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "With Apache Iceberg, you store your big data in the cloud as files (e.g., Parquet), but then query it as if it\u2019s a plain SQL table. You enjoy the endless scalability of the cloud, without having to worry about how to store, partition, or query your data efficiently. PyIceberg is the Python implementation of Apache Iceberg that loads your Iceberg tables into PyArrow (pandas), DuckDB, or any of your preferred engines for doing data science. This means that with PyIceberg, you can tap into big data easily by only using Python. It\u2019s time to say goodbye to the ancient Hadoop-based frameworks of the past! In this talk, you'll learn why you need Iceberg, how to use it, and why it is so fast.", "description": "Description: Working with high volumes of data has always been complex and challenging. Querying data with Spark requires you to know how the data is partitioned, otherwise, your query performance suffers tremendously. The Apache Iceberg open table format fixes this by fixing the underlying storage, instead of by educating the end users. Iceberg originated at Netflix and provides a cloud-native layer on top of your data files. It solves traditional issues regarding correctness by supporting concurrent reading and writing to the table. Iceberg improves performance dramatically by collecting metrics on the data, having the ability to easily repartition your data, and being able to compact the underlying data. Finally, it supports time travel, so the model that you're training doesn't change because new data has been added. After this talk, you'll be comfortable using Apache Iceberg.\r\n\r\nMinutes 0-5: History and why we need a table format\r\nMinutes 5-15: Overview of Iceberg, and how it works under the hood\r\nMinutes 15-30: Introduction to PyIceberg with code and real examples (notebook!!)", "recording_license": "", "do_not_record": false, "persons": [{"id": 86, "code": "UEAYJF", "public_name": "Fokko Driesprong", "biography": "Open Source enthousiast. Committer on Avro, Parquet, Druid, Airflow and Iceberg. Apache Software Foundation members.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 3": [{"id": 267, "guid": "e82f37c8-03f9-5cb5-92f2-8f157924b59d", "logo": "", "date": "2023-09-14T09:30:00+02:00", "start": "09:30", "duration": "00:50", "room": "Room 3", "slug": "cfp-267-keynote-vicki-boykis", "url": "https://amsterdam2023.pydata.org/cfp/talk/QLDEXB/", "title": "Keynote Vicki Boykis", "subtitle": "", "track": null, "type": "Keynote", "language": "en", "abstract": "Lorem ipsum dolor", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [{"id": 283, "code": "3G8JD7", "public_name": "Vicki Boykis", "biography": "Vicki Boykis works on end-to-end ML applications. Her interests include the intersection of information retrieval and large language models, applying engineering best practices to machine learning, and Nutella.  She works at Duo Security and she lives in Philadelphia with her family. Her favorite hobby was making terrible jokes on Twitter when it was still good. She recently wrote a deep dive on embeddings and put together Normconf, celebrating normcore workflows in ML.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 248, "guid": "21e0cc6f-bb25-5f30-8afd-896a68790937", "logo": "", "date": "2023-09-14T10:30:00+02:00", "start": "10:30", "duration": "00:30", "room": "Room 3", "slug": "cfp-248-what-the-pdep-an-overview-of-some-upcoming-pandas-changes", "url": "https://amsterdam2023.pydata.org/cfp/talk/8VRXAN/", "title": "What the PDEP? An overview of some upcoming pandas changes", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Last year, the pandas community adopted a new process for making significant changes to the library: the Pandas Enhancement Proposals, aka PDEPs. In the meantime, several of those proposals have been proposed and discussed, and some already accepted. This talk will give an overview of some of the behavioural changes you can expect as a pandas user.", "description": "Last year, the pandas community adopted a new process for making significant changes to the library: the Pandas Enhancement Proposals, aka PDEPs (similar to Python's PEPs and numpy's NEPs, ..). In the meantime, several of those proposals have been proposed and discussed, and some already accepted, shaping up the pandas roadmap (https://pandas.pydata.org/about/roadmap.html). \r\n\r\nThe goal of this talk is to introduce you to this new process, and give an overview of a few of the proposed PDEPs. This way, you will learn about some of the behavioural changes you can expect as a pandas user in the near future. \r\n\r\nOver the many years of development, pandas has grown (or kept since the early days) quite some corner cases and inconsistencies. Some of the proposed PDEPs are an attempt to tackle those? For example, one accepted proposal is to ban any (up)casting in \"setitem-like\" operations, avoiding surprising data type changes. There is also a proposal to stop providing the inplace option for many methods, because even though the name might imply otherwise, those operations were not actually done in-place. Another major change that is under way is a change to the copy and view semantics of operations in pandas (related to the well-known (or hated) SettingWithCopyWarning). This is already available as an experimental opt-in to test and use the new behaviour, and will probably be a highlight of pandas 3.0.", "recording_license": "", "do_not_record": false, "persons": [{"id": 215, "code": "BFXEQG", "public_name": "Joris Van den Bossche", "biography": "I am a core contributor to Pandas and Apache Arrow, and maintainer of GeoPandas. I did a PhD at Ghent University and VITO in air quality research and worked at the Paris-Saclay Center for Data Science. Currently, I work at Voltron Data, contributing to Apache Arrow, and am a freelance teacher of python (pandas) at Ghent University.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 265, "guid": "82e3db42-5170-5eac-ad21-977d67e729b8", "logo": "", "date": "2023-09-14T11:20:00+02:00", "start": "11:20", "duration": "00:30", "room": "Room 3", "slug": "cfp-265-turning-your-data-ai-algorithms-into-full-web-applications-in-no-time-with-taipy", "url": "https://amsterdam2023.pydata.org/cfp/talk/8RRMCK/", "title": "Turning your Data/AI algorithms into full web applications in no time with Taipy", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Numerous packages exist within the Python open-source ecosystem for algorithm building and data visualization. However, a significant challenge persists, with over 85% of Data Science Pilots failing to transition to the production stage.\r\n\r\nThis talk introduces Taipy, an open-source Python library for front-end and back-end development. It enables Data Scientists and Python Developers to create pilots and production-ready applications for end-users.\r\n\r\nIts syntax facilitates the creation of interactive, customizable, and multi-page dashboards with augmented Markdown. Without the need for web development expertise (no CSS or HTML), users can generate highly interactive interfaces. \r\n\r\nAdditionally, Taipy is engineered to construct robust and tailored data-driven back-end applications. Intuitive components like pipelines and data flow orchestration empower users to organize and manage data effectively. Taipy also introduces a unique Scenario Management functionality, facilitating \"what-if\" analysis for data scientists and end-users.", "description": "During this talk, we will showcase the capabilities of Taipy:\r\n- to create highly-interactive applications easily without any knowledge in web development.\r\n- to fill a void within the standard Python back-end stack, offering a powerful solution for data-driven applications.", "recording_license": "", "do_not_record": false, "persons": [{"id": 276, "code": "9SDZVU", "public_name": "Florian Jacta", "biography": "- Specialist of Taipy, a low-code open-source Python package enabling Python developers to develop a production-ready AI application quickly. Package pre-sales and after-sales function.\r\n\r\n- Data Scientist for Groupe Les Mousquetaires (Intermarche) and ATOS. \r\n\r\n- Developed several Predictive Models as part of strategic AI projects.\r\n\r\n- Master in Applied Mathematics from INSA, Major in Data Science and Mathematical Optimization.", "answers": []}, {"id": 277, "code": "XCD8AN", "public_name": "Alexandre Sajus", "biography": "Alex worked in Amazon Business Intelligence. He graduated with a Master of Engineering at CentraleSup\u00e9lec - Paris-Saclay University and joined Taipy as a Community Success Consultant. His primary skills are MLOps, Machine Learning, Data Engineering, and Python.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 69, "guid": "9a85e18c-c167-5721-994b-8a15333fe5af", "logo": "", "date": "2023-09-14T12:00:00+02:00", "start": "12:00", "duration": "00:30", "room": "Room 3", "slug": "cfp-69-tables-as-code-the-journey-from-ad-hoc-scripts-to-maintainable-etl-workflows-at-booking-com", "url": "https://amsterdam2023.pydata.org/cfp/talk/LKTDB3/", "title": "Tables as Code: The Journey from Ad-hoc Scripts to Maintainable ETL Workflows at Booking.com", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Until a few years ago, data science & engineering at Booking.com had grown largely in an ad-hoc manner. This growth has led to a labyrinth of unrelated scripts representing Extract-Transform-Load (ETL) processes. Without options for quickly testing cross-application interfaces, maintenance and contribution grew unwieldy, and debugging in production was a common practice.\r\n\r\nOver the past several years, we\u2019ve spearheaded a transition from isolated workflows to a well-structured community-maintained monorepo - a task that required not just technical adaptation, but also a cultural shift.\r\n\r\nCentral to this transformation is the adoption of the concept of \"tables as code\", an approach that has changed the way we write ETL. Our lightweight PySpark extension represents table metadata as a Python class, exposing data to code, and enabling efficient unit test setup and validation.\r\n\r\nIn this talk, we walk you through \u201ctables as code\u201d design and complementary tools such as efficient unit testing, robust telemetry, and automated builds using Bazel. Moreover, we will cover the transformation process, including enabling people with non-engineering backgrounds to create fully tested and maintainable ETL. This includes internal training, maintainers, and support strategies aimed at fostering a community knowledgeable in best practices.", "description": "Until a few years ago, data science & engineering at Booking.com had grown largely in an ad-hoc manner. This growth has led to a labyrinth of unrelated scripts representing Extract-Transform-Load (ETL) processes. Without options for quickly testing cross-application interfaces, maintenance and contribution grew unwieldy, and debugging in production was a common practice.\r\n\r\nOver the past several years, we\u2019ve spearheaded a transition from isolated workflows to a well-structured community-maintained monorepo - a task that required not just technical adaptation, but also a cultural shift.\r\n\r\nCentral to this transformation is the adoption of the concept of \"tables as code\", an approach that has changed the way we write ETL. Our lightweight PySpark extension represents table metadata as a Python class, exposing data to code, and enabling efficient unit test setup and validation.\r\n\r\nIn this talk, we walk you through \u201ctables as code\u201d design and complementary tools such as efficient unit testing, robust telemetry, and automated builds using Bazel. Moreover, we will cover the transformation process, including enabling people with non-engineering backgrounds to create fully tested and maintainable ETL. This includes internal training, maintainers, and support strategies aimed at fostering a community knowledgeable in best practices.\r\n\r\nThis talk is aimed at ETL-adjacent data science practitioners, ideally who have been wondering how to push code quality forward at a data-centric organization.\r\n\r\n\r\nIntroduction (0-5 minutes): We begin by shedding light on the infrastructure that hosted the old scripts, and discuss our motivation for change. It\u2019s worth mentioning that this transformative decision emerged from individual product teams, not from an executive mandate.\r\nTables as Code (10 minutes): We'll then introduce the concept of 'tables as code', detailing how this approach enables efficient testing.\r\nMonorepo Transformation (10 minutes): Building on this foundation, we'll explore how 'tables as code' grew into a vast monorepo with thousands of tests. We'll discuss how we scaled our processes and nurtured this project as a community effort.\r\nCommunity Growth and Future Plans (5 minutes): In our closing segment, we'll share insights gained from growing this project as a community, highlight strategies for orchestrating training, community support, and finally, share our future plans both within and outside our organization.", "recording_license": "", "do_not_record": false, "persons": [{"id": 82, "code": "P7V9RY", "public_name": "Bram van den Akker", "biography": "Bram van den Akker is a Senior Machine Learning Scientist at Booking.com with a background in Computer Science and Artificial Intelligence from the University of Amsterdam.  At Booking.com, Bram has been one of the founders of bkng-data, an internal collection of Python tools aimed at improving code quality, testing, and streamlining CI/CD for data practitioners.\r\n\r\nAside from bkng-data, Bram's work focuses on bridging the gap between applied research and practical requirements for Bandit Feedback all across Booking.com. Previously, Bram has held positions at Shopify, Panasonic & Eagle Eye Networks, and has peer reviewed contributions and tutorials to conferences and workshops such as TheWebConf (WWW), RecSys, and KDD, including a best-paper award.", "answers": []}, {"id": 87, "code": "SSFXPC", "public_name": "Jon Smith", "biography": "Jon Smith is a Senior Machine Learning Scientist at Booking.com, having spent his time working in fraud detection and performance marketing. In these areas, he focusses on strengthening software practices within critical ML systems, through evangelising code quality and unit testing.\r\n\r\nHe studied Mathematics and Computer Science at Acadia University and Simon Fraser University in Canada, and spent some time as a Machine Learning Engineer at the Canadian Broadcasting Corporation.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 72, "guid": "f8de93a7-8a01-5b3c-ab6a-bafed8754db1", "logo": "", "date": "2023-09-14T13:30:00+02:00", "start": "13:30", "duration": "00:30", "room": "Room 3", "slug": "cfp-72-graph-neural-networks-for-real-world-fraud-detection", "url": "https://amsterdam2023.pydata.org/cfp/talk/TUTRCX/", "title": "Graph Neural Networks for Real World Fraud Detection", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Fraud is a major problem for financial services companies. As fraudsters change tactics, our detection methods need to get smarter. Graph neural networks (GNNs) are a promising model to improve detection performance. Unlike traditional machine learning models or rule-based engines, GNNs can effectively learn from subtle relationships by aggregating neighborhood information in the financial transaction networks. However, it remains a challenge to adopt this new approach in production.\r\n\r\nThe goal of this talk is to share best practices for building a production ready GNN solution and hopefully spark your interest to apply GNNs to your own use cases.", "description": "In this talk, we focus on suspicious account detection for online marketplaces. These platforms allow users to set up shops and sell products with little friction. Unfortunately, this attracts fraudsters who abuse these platforms. We use GNNs to do supervised learning based on accounts previously flagged as fraudulent, so that we can learn from both account properties and the relationship between accounts. However, productionizing GNNs is a big challenge. Addressing this challenge purely using open source packages is the main focus of this talk.\r\n\r\nWe first give an overview of GNN-based fraud detection. Then we deep dive into utilizing PySpark and GraphFrames to build a transaction graph in a scalable way and convert it to DGL (Deep Graph Library) format. Next we share our experiences of setting up training and inference graphs in different time intervals, and deploying the end-to-end model pipeline in Airflow.\r\n\r\nAttendees are required to have a basic understanding of machine learning. In this informative talk, they will gain insights into fraud detection's challenges and learn best practices to productionize GNNs.", "recording_license": "", "do_not_record": false, "persons": [{"id": 91, "code": "7VLGN3", "public_name": "Feng Zhao", "biography": "Feng is a senior data scientist at Adyen. He is passionate about solving real business problems using innovative AI/machine learning approaches. He received his Ph.D. from the National University of Singapore.", "answers": []}, {"id": 95, "code": "ACGTTT", "public_name": "Tingting Qiao", "biography": "Data scientist in Adyen, working in the Score team focusing on fraud detection. \r\n\r\nHaving PhD background in computer vision and natural language processing using deep neural networks. Familiar with prediction models, such as regression, classification models, etc., as well as the latest research techniques, such as adversarial learning, neural networks etc. Several years of experience with popular deep learning frameworks.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 49, "guid": "37b038f8-5842-5f59-b441-c26b96cd2690", "logo": "", "date": "2023-09-14T14:10:00+02:00", "start": "14:10", "duration": "00:30", "room": "Room 3", "slug": "cfp-49-promtly-evaluating-prompts-with-bayesian-tournaments", "url": "https://amsterdam2023.pydata.org/cfp/talk/HZB8JU/", "title": "Promtly Evaluating Prompts with Bayesian Tournaments", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Pick your next hot LLM prompt using a Bayesian tournament! Get a quick LLM dopamine hit with a side of decision theory vegetables. It's Bayesian Thunderdome: many prompts enter, one prompt leaves.", "description": "How do you chose the best LLM prompt systematically beyond guessing and vibes? Use the winner of a Bayesian tournament! Get a quick dopamine hit from fun LLM prompt magic with a side of Bayesian decision theory vegetables. If you are doing stuff with LLMs \u2014 you'll get a serious tool to improve your prompting game. If you're not using LLMs \u2014 you'll learn about Bayesian tournaments. They are not well known but have wide applicability: they help you optimally choose a winner using a minimal number of matches.", "recording_license": "", "do_not_record": false, "persons": [{"id": 62, "code": "J8TDAL", "public_name": "Andy Kitchen", "biography": "I've helped found multiple start-ups, including CorticalLabs an AI+Biotech company working on \"Synthetic Biological Intelligence\". I've co-authored several papers and patents in deep learning and neuroscience. I've made a mess in more than a dozen programming languages over my career. My stack is full. I've worked on custom neural interface hardware to web apps and everything in between. I've won a few hack-a-thons. I started the Machine Learning and AI meetup in Melbourne Australia, helped found & organize the Compose :: Melbourne conference. I have two cats, I scoop their poop most days.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 123, "guid": "4219e333-9d0f-595f-a7ef-8ef7d4cdea8a", "logo": "", "date": "2023-09-14T15:10:00+02:00", "start": "15:10", "duration": "00:30", "room": "Room 3", "slug": "cfp-123-power-users-long-tail-users-and-everything-in-between-choosing-meaningful-metrics-and-kpis-for-product-strategy", "url": "https://amsterdam2023.pydata.org/cfp/talk/8AVDXH/", "title": "Power Users, Long Tail Users, and Everything In Between: Choosing Meaningful Metrics and KPIs for Product Strategy", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Data scientists in industry often have to wear many hats. They must navigate statistical validity, business acumen and strategic thinking, while also representing the end user. In this talk, we will talk about the pillars that make a metric the right one for a job, and how to choose appropriate Key Performance Indicators (KPIs) to drive product success and strategic gains.", "description": "Our presentation will traverse the relationship of data science skills in product strategy - embracing the multifaceted role of the data scientist and navigating the journey from user segmentation to making data-driven decisions.\r\n\r\n1. The Data Scientist's Hat Trick: We initiate by emphasising the assorted roles that a data scientist plays in today's business landscape - from being a statistician ensuring the accuracy and validity of data to a strategist driving business decisions. [5 mins]\r\n\r\n2. Choosing Significant Metrics: Next, we'll delve into the nuances of selecting the right metric for the job. Specifically, we\u2019ll talk about the different pillars of metrics setting, for common data science responsibilities such as randomised controlled trials, offline evaluation, opportunity analysis etc.  [7 mins]\r\n\r\n3. Setting The Right KPIs: Once metrics are defined, we'll venture into setting the correct KPIs - the small set of top line numbers that say if our venture is doing the job. [7 mins]\r\n\r\n4. Data-Driven Decision Making: Lastly, we'll elucidate how to leverage the data you've gathered to make informed, strategic decisions. This necessitates interpreting your metrics and KPIs, spotting trends, and making necessary adjustments to stay on course. [7 mins]\r\n\r\nIncorporating real-world case studies, we'll demonstrate how these concepts intertwine to contribute to product success. \r\n\r\nLearning Objectives:\r\n* Appreciate the multifaceted role of a data scientist in driving product strategies.\r\n* Learn to set realistic and challenging KPIs that align with your company's overarching objectives.\r\n* Gain insights into leveraging data for informed decision-making and product strategy adjustments.\r\n\r\nWho Should Attend:\r\nThis talk is aimed for data professionals, however anyone involved in shaping product strategy and making data-driven decisions could find this useful.", "recording_license": "", "do_not_record": false, "persons": [{"id": 140, "code": "YVBEUN", "public_name": "Alon Nir", "biography": "Data scientist (Data Lead) at Spotify. Dismal scientist by education. Advocating against pie charts since 2015. Self-proclaimed GIF connoisseur.", "answers": []}, {"id": 141, "code": "J7HG8X", "public_name": "Dror A. Guldin", "biography": "Data Scientist (Tech Lead) at Meta", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 270, "guid": "7896c0f3-e1e9-5103-a9af-2976ed5118d5", "logo": "", "date": "2023-09-14T16:00:00+02:00", "start": "16:00", "duration": "00:45", "room": "Room 3", "slug": "cfp-270-lightning-talks", "url": "https://amsterdam2023.pydata.org/cfp/talk/KAGY3B/", "title": "Lightning talks", "subtitle": "", "track": null, "type": "Lightning talks", "language": "en", "abstract": "Lorem ipsum dolor", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}, {"id": 271, "guid": "68f57a2f-125a-57f2-ae71-5ae344efa647", "logo": "", "date": "2023-09-14T17:30:00+02:00", "start": "17:30", "duration": "02:00", "room": "Room 3", "slug": "cfp-271-kickstart-ai-sponsored-drinks-time-location-tbd-", "url": "https://amsterdam2023.pydata.org/cfp/talk/GL7NQD/", "title": "Kickstart AI sponsored drinks [time & location TBD]", "subtitle": "", "track": null, "type": "Social Event", "language": "en", "abstract": "Kickstart AI is a foundation powered by a coalition of iconic Dutch brands (Ahold Delhaize, ING, KLM and NS). Their mission is to accelerate AI adoption in the Netherlands, and improve society through the use of AI.", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}], "Tutorial Room": [{"id": 238, "guid": "1796a41f-f4b9-5498-b08a-069ce827c06d", "logo": "", "date": "2023-09-14T10:30:00+02:00", "start": "10:30", "duration": "01:20", "room": "Tutorial Room", "slug": "cfp-238-designing-a-machine-learning-system", "url": "https://amsterdam2023.pydata.org/cfp/talk/N8DYS7/", "title": "Designing a Machine Learning System", "subtitle": "", "track": null, "type": "Tutorial__", "language": "en", "abstract": "Are you a machine learning practitioner struggling with designing, reasoning, and communicating about ML systems? Then this session is for you! With the industry moving towards end-to-end ML teams to enable them to implement MLOps practices, it is paramount for you to understand ML from a systems perspective. In this hands-on session, you will gain a thorough understanding of the technical intricacies of designing valuable, reliable and scalable ML systems.", "description": "During this session you will improve your understanding of the technical intricacies of designing valuable, reliable and scalable ML systems. With others you will design a machine learning application from scratch, starting with clearly defining business requirements, framing the ML problem, to putting your design to paper. The session enables you to identify trade-offs and bottlenecks in a system. Plus, you\u2019ll learn how to effectively communicate and collaborate with other people on a system design.\r\n\r\nThere will be a mix of theory and practice. We will explain the importance of ML system design, share a common methodology for designing an ML system, and apply it to a real business case. A canvas will be provided physically for following the design methodology, and sheets/whiteboards/post-its to iterate on your design.\r\n\r\nThis session is for all that have worked, or studied, in the field of ML/AI, or have affinity with the subject. The session is technical, but also interesting if you are a (product) manager in the field, as it will allow you to experience how technical designs are executed and ensure the design meets the business requirements. Very little ML algorithm knowledge is required, knowing the difference between classification and regression is enough.\r\n\r\nThis Tutorial is for you if\u2026\r\n-\tYou want to improve your understanding of what makes a scalable machine learning application\r\n-\tYou want to make more conscious decisions when working on machine learning applications\r\n-\tYou want to be better at identifying trade-offs when making design decisions for your machine learning application\r\n-\tYou want to improve communicating your design decisions", "recording_license": "", "do_not_record": false, "persons": [{"id": 36, "code": "VAYEHH", "public_name": "Jetze Schuurmans", "biography": null, "answers": []}, {"id": 135, "code": "GBGTBV", "public_name": "Roy van Santen", "biography": "I'm a Software Engineer who gradually moved into the Machine Learning space. My passion is in building high quality and highly maintainable software systems. I put great effort in CI/CD, layered testing, monitoring/alerting and put special attention to communicating my ideas ensuring everyone is onboard.\r\nTo do this I like using RFC-like process using design docs that serves as documentation for designing software systems.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 202, "guid": "73e8f0d5-c586-5bb5-866f-9071f5bc2d40", "logo": "", "date": "2023-09-14T12:00:00+02:00", "start": "12:00", "duration": "01:00", "room": "Tutorial Room", "slug": "cfp-202-uncertainty-visualization-with-arviz", "url": "https://amsterdam2023.pydata.org/cfp/talk/DH3N3R/", "title": "Uncertainty visualization with ArviZ", "subtitle": "", "track": null, "type": "Tutorial_", "language": "en", "abstract": "Learn how to visualize uncertainty in parameters or predictions using mutiple visualizations adapted to your data and task", "description": "This tutorial will cover 4 different plots designed to visualize uncertainty: quantile dotplots, empirical cumulative density functions, histograms and kernel density estimates. Finding optimal solutions in data visualization requires adapting the plots to both the data and task at hand, so we will start explaining each of them, their main pros and cons, how to interpret and how to generate each of those plot with ArviZ. We will then cover multiple data visualization tasks on several datasets to put those skills in practice and extend and deepen our \"visualization space\", both what you know and what you are comfortable enough to use.", "recording_license": "", "do_not_record": true, "persons": [{"id": 208, "code": "PR9EUR", "public_name": "Oriol Abril Pla", "biography": "Oriol (he/him/ell) is a computational statistician with a passion for open source, teaching and community building. He currently works as open source maintainer of ArviZ and PyMC, both Python libraries related to Bayesian modeling and sponsored by NumFOCUS. He is also an instructor at Intuitive Bayes and has taught a couple undergrad courses on maths and statistics as external lecturer.\r\n\r\nHe has led both virtual and in-person workshops and talks at Data Umbrella, PyDataBCN and PyData Global. He is also involved in PyMCon organization.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 229, "guid": "e054832c-e8fd-56bb-987b-1ce5eb94d7dd", "logo": "", "date": "2023-09-14T13:30:00+02:00", "start": "13:30", "duration": "01:30", "room": "Tutorial Room", "slug": "cfp-229-probabilistic-predictions-probabilistic-forecasting-with-sktime-and-probabilistic-regression-with-skpro", "url": "https://amsterdam2023.pydata.org/cfp/talk/F8EW7P/", "title": "Probabilistic predictions: probabilistic forecasting with sktime and probabilistic regression with skpro", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "Probabilistic predictions are predictions that include some statements about uncertainty of the prediction, e.g., prediction intervals that make statements about a likely range of values that a prediction can take.\r\nThis workshop gives an introduction on making probabilistic predictions with the sktime and skpro python packages, for forecasting and supervised regression. Both packages are sklearn-compatible, built using skbase, with composable and modular interfaces.\r\nThe presentation includes a practical primer of different types of probabilistic predictions, algorithms and estimators, and evaluation workflows, with python code examples.", "description": "Probabilistic predictions make statements about the uncertainty or likely variation of the forecast, e.g., intervals at nominal coverage or conditional distributions.\r\nThey appear in probabilistic forecasting as well as in probabilistic supervised (tabular) regression.\r\nThis tutorial presents probabilistic forecasting capability in the skpro and sktime packages, combined with a methodological overview.\r\n\r\nsktime is a widely used package for time series, skpro covers probabilistic (tabular) regression. Both are based on skbase, and designed for interoperability with each other and sklearn.\r\n\r\nThis tutorial presents the joint designs for probabilistic predictions and modular estimator interfaces. It also gives an overview of pipelines, tuning using probabilistic metrics, and compositors that can be used to turning any point forecaster into probabilistic forecasters, such as conformal or empirical interval estimators.\r\n\r\nThe presentation will showcase skpro and sktime, for tabular and time series tasks:\r\n- probabilistic prediction interfaces\r\n- metrics, e.g., quantile loss, or CRPS, log-loss for distribution forecasts\r\n- tuning using probabilistic metrics\r\n- conformal probabilistic intervals for any pipeline\r\n- compositors to make any point prediction estimator probabilistic\r\n- for time series: hierarchical and global probabilistic forecasts, reduction to regression\r\n\r\nFrom a methodological perspective, we will cover:\r\n\u2022\tinterval forecasts: producing intervals with a nominal probability of the observation to be contained in the interval\r\n\u2022\tquantile forecasts: specifying one or multiple quantiles of a predictive forecast distribution\r\n\u2022\tfully probabilistic forecasts: producing a symbolic representation of a predictive forecast distribution\r\n\u2022\tsimulators or samplers from probabilistic forecasting models\r\nAs research on software interfaces and mathematical conceptualization in this area is still an ongoing endeavour, challenges will also be discussed, with invitations to contribute.\r\nsktime and skpro are developed by an open community, with aims of ecosystem integration in a neutral, charitable space. We welcome contributions and seek to provides opportunity for anyone worldwide.", "recording_license": "", "do_not_record": false, "persons": [{"id": 218, "code": "LWDWDN", "public_name": "sktime community", "biography": "(1 speaker will attend if accepted, exact speaker tbd)", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 9, "guid": "20780d65-1ec2-51f9-b7e2-ab25c930becc", "logo": "", "date": "2023-09-14T15:10:00+02:00", "start": "15:10", "duration": "00:30", "room": "Tutorial Room", "slug": "cfp-9-unconference-interviews-tips-and-stories-from-both-sides", "url": "https://amsterdam2023.pydata.org/cfp/talk/CKKZRM/", "title": "Unconference: Interviews: Tips and Stories from Both Sides", "subtitle": "", "track": null, "type": "Unconference", "language": "en", "abstract": "You are a data science or a machine learning engineering, and you applied for a position. You thought your interview went well, but still got a negative response... What might went wrong? In this talk, we will explore how things may go wrong from both applicant and interviewer side, and what can you do about it.", "description": "You studied for years, and maybe have years of industry experience in your pocket. You found a nice opportunity and you applied for the job position. You did your best, but still got rejected. Two things for sure are that you are not alone, and it will not be your first time. But how did the interviewers reach to that decision? Could it be about your technical level, the colour of your shirt, or the interviewer did not have enough coffee that morning?\r\n\r\nIn this talk I you will hear about stories, tips and how technical interviewers may reach to a decision:\r\n- What are the red flags from both applicant and interviewer sides?\r\n- How interviews might go wrong from both the applicant and the interviewer sides?\r\n- What should you expect from your technical interviews?\r\n- How can we structure a better interview process?\r\n\r\nWhether you are hiring or applying, you will have a better understand what is happening at the other side of the table!", "recording_license": "", "do_not_record": false, "persons": [{"id": 21, "code": "RVY89X", "public_name": "Kemal Tugrul Yesilbek", "biography": "Kemal is a Technical Lead in a data science team at ABN AMRO. He studied software engineering and machine learning. During his time in academia, he published machine learning solutions approaching human-level performance.\r\n\r\nKemal started his career as a data scientist. He founded Elify.io, a skill assessment tool for data-driven roles, which resulted in an exit. He is working as a machine learning engineer for the past years, delivering end-to-end machine learning-backed solutions.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 279, "guid": "38fcc911-f1bf-53f2-a217-fa7979592794", "logo": "", "date": "2023-09-14T15:50:00+02:00", "start": "15:50", "duration": "00:30", "room": "Tutorial Room", "slug": "cfp-279-unconference-2", "url": "https://amsterdam2023.pydata.org/cfp/talk/3LZ933/", "title": "Unconference #2", "subtitle": "", "track": null, "type": "Unconference", "language": "en", "abstract": "Lorem ipsum dolor", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}]}}, {"index": 2, "date": "2023-09-15", "day_start": "2023-09-15T04:00:00+02:00", "day_end": "2023-09-16T03:59:00+02:00", "rooms": {"Room 1": [{"id": 8, "guid": "b1316bcc-7a02-5d20-83ac-77806aa91efd", "logo": "", "date": "2023-09-15T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 1", "slug": "cfp-8-innovation-in-the-age-of-regulation-federated-learning-with-flower", "url": "https://amsterdam2023.pydata.org/cfp/talk/WTEANG/", "title": "Innovation in the Age of Regulation: Federated Learning with Flower", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "With the rise of data privacy concerns around AI in the EU, how can we innovate using AI capabilities despite regulations around consumer data? What tools and features are available to help us build AI in regulated industries? This talk will discuss how we can leverage diverse datasets to build better AI models without ever having to touch the datasets by using a Python library called Flower.", "description": "In this talk, we\u2019ll review the importance of data privacy concerns, particularly in the EU, and address how we can build AI using sensitive data. We'll discuss a few machine learning techniques (classical, distributed and federated learning), and show how federated learning can help us train AI models without ever touching the sensitive data. \r\n\r\nThen, we'll evaluate a few main open source Python packages that help engineers get started with federated learning and why Flower is a valuable option to consider for your next project. We'll review the core features of Flower; most notably, it's ease of use.\r\n\r\nAfter that, we\u2019ll jump into a demo and show how, with minimal code, a Python engineer can orchestrate a training job with multiple data sources using federated learning. We\u2019ll walk through different parameters that give engineers the power to control and fine tune the server without the hassle of knowing infrastructure or cloud architecture.\r\n\r\nBy the end of this talk, you\u2019ll be able to:\r\n\r\n* Understand the role of federated learning in a landscape with increasing regulation around AI, particularly in the EU with the proposed Artificial Intelligence Act\r\n* Differentiate between federated learning and classical machine learning\r\n* Design your project so that it is in compliance with current and future legislation passed on how to use personal data\r\n* Build and fine tune a server that hosts the model weights for a model trained without seeing personal data\r\n* Understand options available to increase the privacy around the data that is used to train the model\r\n\r\nThere will be a link to a Github repo at the end of the talk that contains all the code used in the demo in order to help you get started with your first federated learning project.", "recording_license": "", "do_not_record": false, "persons": [{"id": 20, "code": "PWZMWE", "public_name": "Krishi Sharma", "biography": "Krishi Sharma is a software developer at KUNGFU.AI where she builds software applications that power machine learning models and deliver data for a broad range of services. As a former data scientist and machine learning engineer, she is passionate about building tools that ease the infrastructure dependencies and reduce potential technical debt around handling data. She helped build and maintains an internal Python tool, Potluck, which allows machine learning engineers the ability to bootstrap a containerized, production ready application with data pipelining templates so that her team can focus on the data and metrics without squandering too much time finagling with deployment and software", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 198, "guid": "8f739f49-0ed3-5db9-99bc-b4d02ae9ad97", "logo": "", "date": "2023-09-15T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 1", "slug": "cfp-198-using-kubernetes-as-your-multi-tenant-orchestration-layer", "url": "https://amsterdam2023.pydata.org/cfp/talk/V9JSC9/", "title": "Using Kubernetes as your multi-tenant orchestration layer", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Introducing Kubernetes as the orchestration layer for your on-premise data platform poses multiple challenges. From GitOps to introducing Spark and finally setting up stateful application like postgres.", "description": "Hadoop and big data used to be synonyms for each other. However, as time progressed, the tech stack community grew smaller and cloud-native technologies have taken the main stage. When your data platform consists out of multiple servers, the orchestration layer becomes a crucial part of the infrastructure. This is where Kubernetes comes in as the obvious successor of Yarn. Still, there are many hurdles to be able to set this up as a multi-tenant orchestrator on an on-premise data cluster. This presentation will cover why you need an orchestrator and the common challenges. From introducing Kubernetes itself and setting up a secure GitOps approach. To introducing data tools like Trino, Spark and Jupyterhub. And finally introducing stateful applications like Postgres databases and Kafka clusters.", "recording_license": "", "do_not_record": false, "persons": [{"id": 204, "code": "YDERCX", "public_name": "Jorrick Sleijster", "biography": "Jorrick is an experienced Data Platform Engineer in the payments industry. With a background in computer science his focus has been on introducing and maintaining tools on the data platform. On the side Jorrick is an active open-source contributor to pet projects and Apache Airflow. One of the contributions was awarded with PR-of-the-month of the Apache Airflow project.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 55, "guid": "4edb2500-cc63-510c-9d30-5dd259022b4a", "logo": "", "date": "2023-09-15T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 1", "slug": "cfp-55-let-s-exploit-pickle-and-skops-to-the-rescue-", "url": "https://amsterdam2023.pydata.org/cfp/talk/88HSMQ/", "title": "Let\u2019s exploit pickle, and `skops` to the rescue!", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Pickle files can be evil and simply loading them can run arbitrary code on your system. This talk presents why that is, how it can be exploited, and how `skops` is tackling the issue for scikit-learn/statistical ML models. We go through some lower level pickle related machinery, and go in detail how the new format works.", "description": "The pickle format has many vulnerabilities and loading them alone can run arbitrary code on the user\u2019s system [1]. In this session we go through the process used by the pickle module to persist python objects, while demonstrating how they can be exploited. We go through how `__getstate__` and `__setstate__` are used, and how the output of a `__reduce__` method is used to reconstruct an object, and how one can have a malicious implementation of these methods to create a malicious pickle file without knowing how to manually create a pickle file by manipulating a file on a lower level. We also briefly touch on other known exploits and issues related to the format [2]. \r\n\r\nWe also show how one can look inside a pickle file and the operations run by it while loading it, and how one could get an equivalent python script which would result in the output of the pickle file [3]\r\nThen I present an alternative format from the `skops` library [4] which can be used to store scikit-learn based models. We talk about what the format is, and how persistence and loading is done, and what we do to prevent loading malicious objects or to avoid running arbitrary code. This format can be used to store almost any scikit-learn estimator, as well as xgboost, lightgbm, and catboost models.\r\n\r\n- [1] https://peps.python.org/pep-0307/#security-issues\r\n- [2] https://github.com/moreati/pickle-fuzz\r\n- [3] https://github.com/trailofbits/fickling\r\n- [4] https://skops.readthedocs.io/en/stable/persistence.html", "recording_license": "", "do_not_record": false, "persons": [{"id": 69, "code": "9HRCVS", "public_name": "Adrin", "biography": "Adrin works on a few open source projects including skops which tackles some of the MLOps challenges related to scikit-learn models. He has a PhD in Bioinformatics, has worked as a consultant, and in an algorithmic privacy and fairness team. He's also a core developer of scikit-learn and fairlearn.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 37, "guid": "cd77e690-a63f-564c-8a15-5da291b8040f", "logo": "", "date": "2023-09-15T13:00:00+02:00", "start": "13:00", "duration": "00:30", "room": "Room 1", "slug": "cfp-37-mastering-recommendation-systems-evaluation-an-a-b-testing-approach-with-insights-from-the-industry", "url": "https://amsterdam2023.pydata.org/cfp/talk/X8UY37/", "title": "Mastering Recommendation Systems Evaluation: An A/B Testing Approach with Insights from the Industry", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Recommendation systems shape personalized experiences across various sectors, but evaluating their effectiveness remains a significant challenge. Drawing on experiences from industry leaders such as Booking.com, this talk introduces a robust, practical approach to A/B testing for assessing the quality of recommendation systems. The talk is designed for data scientists, statisticians, and business professionals, offering real-world insights and industry tricks on setting up A/B tests, interpreting results, and circumventing common pitfalls. While basic familiarity with recommendation systems and A/B testing is beneficial, it's not a prerequisite.", "description": "This talk aims to provide attendees with a practical understanding of A/B testing in the evaluation of recommendation systems, including unique insights from industry practices and specific tricks that enhance effectiveness.\r\n\r\nMy report includes next steps:\r\n- Introduction to recommendation systems, their ubiquity, and the imperative for evaluation, including industry examples.\r\n- An overview of A/B testing and its vital role in assessing recommendation systems, supported by insights from Booking.com and other industry leaders.\r\n- Techniques for designing effective hypotheses for A/B tests, focusing on recommendation systems.\r\n- Choosing pertinent metrics for robust evaluation of recommendation systems with industry examples.\r\n- Conducting A/B tests: industry best practices, common pitfalls, and strategies for mitigation, reinforced by real-world cases.\r\n- Accurate interpretation of A/B testing results and management of statistical biases, with insights from the field.\r\nBy the end of the talk, attendees will have a comprehensive understanding of how to apply A/B testing effectively to recommendation systems, select relevant metrics, interpret results accurately, and navigate common challenges, backed by industry best practices and practical examples.", "recording_license": "", "do_not_record": false, "persons": [{"id": 48, "code": "X9THZF", "public_name": "ildar safilo", "biography": "- Machine Learning Scientist in the Booking.com\r\n- Experienced manager in MLE/DS/SE/DA, I possess extensive expertise in machine learning, analytics, and software engineering. I excel at leading teams to create groundbreaking businesses and delivering innovative solutions for real-world business cases across various industries, including IT, banking, telecommunications, marketplaces, game development, shops, Travel-tech and streaming platforms.\r\n- Expert in building recommendation and ranking systems, as well as personalization automation with machine learning, and advanced A/B testing.\r\n- Co-author and lecturer of a popular online course on recommender system development with over 1000 students.\r\n- Co-author an open-source Python library called RecTools, specifically designed for building recommender systems. The library is hosted on GitHub at RecTools and has received widespread recognition and adoption in the industry.\r\n- Graduate with a Master\u2019s degree in Mathematics and Computer Science and over 6 years of experience in data science.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 133, "guid": "f418d8b0-4976-5fb0-ab84-49ddfeff58d2", "logo": "", "date": "2023-09-15T13:40:00+02:00", "start": "13:40", "duration": "00:30", "room": "Room 1", "slug": "cfp-133-to-one-hot-or-not-a-guide-to-feature-encoding-and-when-to-use-what", "url": "https://amsterdam2023.pydata.org/cfp/talk/3V9ZZX/", "title": "To One-Hot or Not: A guide to feature encoding and when to use what", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Have you ever struggled with a multitude of columns created by One Hot Encoder? Or decided to look beyond it, but found it hard to decide which feature encoder would be a good replacement? \r\n\r\nGood news, there are many encoding techniques that have been developed to address different types of categorical data. This talk will provide an overview on various encoding methods available in data science, and a guidance on decision making about which one is appropriate for the data at hand. \r\n\r\nJoin this talk if you would like to hear about the importance of feature encoding and why it is important to not default to One Hot Encoding in every scenario. It will start with commonly used approaches and will progress into more advanced and powerful techniques which can help extract meaningful information from the data.\r\n\r\nFor each presented encoder, after this talk you will know: \r\n- When to use it\r\n- When NOT to use it\r\n- Important considerations specific to the encoder\r\n- Python library that offers a built-in method with the encoder, facilitating easy integration into feature engineering pipelines.", "description": "I will explore different feature encoding approaches and provide guidance for decision-making. I will cover simpler methods like Label, One Hot, and Frequency encoding, progressing to powerful techniques like Target and Rare Label encoding. Finally, I will explain more complex approaches like Weight of Evidence, Ratio of Probabilities, Decision Tree, and Catboost encoding. I will close the talk with summarizing the key takeaways.\r\n\r\nTarget Audience: \r\nData scientists and anyone interested in feature encoding\r\n\r\nPrevious experience with feature encoders can be useful but is not mandatory to follow the talk.", "recording_license": "", "do_not_record": false, "persons": [{"id": 144, "code": "9AAUTS", "public_name": "Ana Chaloska", "biography": "Ana is a data scientist experienced in the payments industry with a focus on the risk domain. With background in information and data science, she has contributed to building ML solutions for mitigating customer risk and optimizing customer monitoring processes.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 170, "guid": "da6b1185-bfaf-568b-a2dd-2e5236440ea2", "logo": "", "date": "2023-09-15T14:20:00+02:00", "start": "14:20", "duration": "00:30", "room": "Room 1", "slug": "cfp-170-survival-analysis-a-deep-dive", "url": "https://amsterdam2023.pydata.org/cfp/talk/ATV7NC/", "title": "Survival Analysis: a deep dive", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Survival analysis was initially introduced to handle the data analysis required in use cases revolving death and treatment in health care. Due to its merit, this method has spread to many other domains for analyzing and modeling the data where the outcome is the time until an event of interest occurs. Domains such as finance, economy, sociology and engineering. \r\n\r\nThis talk aims at unraveling the potential of survival analysis with examples from different domains. A taxonomy of the existing descriptive and predictive analytics algorithms in survival analysis are demonstrated. The concept of some candidate algorithms from each group are explained in detail, along with an example and implementation guideline using the right open source framework.", "description": "This talk aims at introducing the tools and techniques within the survival analysis domain for analyzing the time until an event of interest occurs. Examples of such event are rehospitalization after being discharged from hospital (healthcare), device needing maintenance after (re)commissioning (manufacturing), finding a job after unemployment (economy), an asset being sold after listing for sale (real-estate/finance), getting rearrested after being released from prison (criminology/sociology), and many other examples. \r\n\r\nThe potential of survival analysis tools, in both descriptive and predictive analytics, are hidden to the data science community. As a result of this, such problems are often formulated as classification or regression, where this also comes with its own caveats and pitfalls. \r\n\r\nThe aim of the talk is to simplify methods and algorithms in survival analysis with some shallow mathematical focus and starts by raising awareness about survival analysis and its potential and applications for the general audience. The descriptive and predictive algorithms within survival analysis address the data scientists with basic statistics and machine learning background, as the main audience of the talk. \r\n\r\n- Introduction to Survival Analysis\r\n- Applications in different domains\r\n- Formulating Survival Analysis Problem\r\n- Taxonomy of Descriptive & Predictive Methods with python packages\r\n- Overview of Descriptive Methods\r\n          - Kaplan-Meier [3 slide] \r\n          - Nelson-Aalen & Weibull [half slide]\r\n- Overview of Predictive Methods\r\n           - Cox Proportional Hazard [3 slide]\r\n           - Survival Tree & Forrest [1 slide]\r\n           - Deep Survival Analysis [1 slide]\r\n- Conclusion\r\n\r\nAt the end of the talk, the audience becomes aware of what survival analysis can do and which algorithms, with their corresponding python package, are the low hanging fruit in a data scientist toolbox. In addition, the audience will gain a structured overview on the topic so that any need for further knowledge acquisition could be independently followed in the future.", "recording_license": "", "do_not_record": false, "persons": [{"id": 179, "code": "CNG9QJ", "public_name": "Danial Senejohnny", "biography": "I am a data scientist with a background in applied mathematics (systems & control). In my career as data scientist, I have experienced different sectors, i.e. manufacturing, cybersecurity, healthcare, and finance. Currently, I am contributing to data-driven solutions that improve our clients\u2019 experience and satisfaction within ABN AMRO.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 114, "guid": "cbb0b87d-a8ba-536e-b126-878f6600ff69", "logo": "", "date": "2023-09-15T15:20:00+02:00", "start": "15:20", "duration": "00:30", "room": "Room 1", "slug": "cfp-114-deep-look-into-deepfakes-mastering-creation-impact-and-detection", "url": "https://amsterdam2023.pydata.org/cfp/talk/NZJTVC/", "title": "Deep look into Deepfakes: Mastering Creation, Impact, and Detection", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Deepfakes, a form of synthetic media where a person's image or video is seamlessly replaced using Generative AI like GANs, have recieved significant attention. This talk aims to provide a comprehensive exploration of deepfakes, covering their creation process, positive and negative effects, development pace, and tools for detection. By the end of the presentation, attendees will be equipped with how to create and detect deepfakes, a deep understanding of the technology and its impact.", "description": "Talk Outline:\r\n\r\nI. How Deepfakes Work (Approx. 8 minutes)\r\n\r\n- Step-by-step explanation of deepfake creation using an opensource tool\r\n- Clarifying the technical aspects behind manipulating existing media with AI algorithms\r\n\r\nII. Deepfakes with GANs (Approx. 8 minutes)\r\n\r\n- Introduction to Generative Adversarial Networks (GANs) and their role in deepfake generation\r\n- Different types of GANs and how to craft realistic deepfakes\r\n\r\nIII. The Good and the Bad (Approx. 8 minutes)\r\n\r\n- Exploring the positive effects of deepfakes\r\n- Unveiling the negative implications of deepfakes\r\n- Real-world examples highlighting the ethical concerns\r\n- Speculating on the future developments of deepfake technology\r\n\r\nIV. How to Recognize Deepfakes (Approx. 6 minutes)\r\n\r\n- Insight into the ongoing efforts to combat the misuse of deepfakes\r\n- Various approaches and AI-driven tools for detecting deepfake media \r\n- Understanding the limitations in detecting increasingly sophisticated deepfakes\r\n\r\nKey Takeaways:\r\n\r\n- In-depth understanding of deepfake creation and the role of GANs\r\n- Awareness of the positive and negative impacts of deepfakes in different domains\r\n- Real-world examples illustrating the ethical concerns surrounding deepfakes\r\n- Insights into the future trends and advancements in deepfake technology\r\n- Familiarity with a range of AI-based approaches and tools for detecting deepfakes", "recording_license": "", "do_not_record": false, "persons": [{"id": 67, "code": "PLFFYV", "public_name": "Maryam Miradi", "biography": "Maryam Miradi is AI and Data Science Lead at Transactie Monitoring Nederland (TMNL). She has a PhD in Artificial Intelligence Deep Learning, specialised in NLP and Computer Vision from Delft University of Technology. The last 15 years, she has developed different AI solutions for Organisations such as Ahold-Delhaize, Belastingdienst, Alliander, Stedin and ABN AMRO", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 2": [{"id": 74, "guid": "79731e0e-a1d2-597c-88a9-69920acd5d09", "logo": "", "date": "2023-09-15T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 2", "slug": "cfp-74-a-data-driven-approach-for-distributing-scarce-goods-within-the-rewe-retail-supply-chain", "url": "https://amsterdam2023.pydata.org/cfp/talk/7UCW7S/", "title": "A data-driven approach for distributing scarce goods within the REWE retail supply chain", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Global political circumstances and unpredictable crises such as the Covid-19 pandemic can cause a scarcity of grocery goods within the retail supply chain. We present a data-driven approach to ensure a fair and replicable distribution from the supplier to the retail warehouses at REWE, one of the largest grocery chains in Germany.", "description": "Optimizing the distribution of scarce perishable goods presents a complex challenge in the retail industry.  It requires balancing logistical constraints such as pallet weight and truck capacities with the need to ensure a fair distribution of goods according to available stock and customer demand. In this talk, we offer insights into the solutions we have developed to tackle this problem. \r\n\r\nWe will begin by discussing our initial approach, which involves employing a greedy algorithm for distributing one product at a time. We will then delve into an enhanced simultaneous multi-product distribution approach, which constitutes a discrete optimization problem with nonlinear constraints and unfeasible combinatorial search spaces. We present our approach to reduce the complexity of the optimization problem and use algorithms from the scipy library to ensure stable converging solutions. Throughout, we will discuss advantages and disadvantages of the approaches used. \r\n\r\nFurthermore, we will provide an overview of our tech stack, leveraging the Google Cloud architecture. Additionally, we will discuss our utilization of the Streamlit framework, enabling us to create an interactive dashboard that empowers users to leverage our optimization approaches in addressing upcoming challenges effectively.", "recording_license": "", "do_not_record": true, "persons": [{"id": 94, "code": "9DHHK3", "public_name": "Robert Grimm", "biography": "Data Scientist at REWE Group. Previously worked as Data Scientist in the chemical industry (Covestro AG). Prior to working in industry, earned a PhD in Computational Psycholinguistics (University of Antwerp).", "answers": []}, {"id": 104, "code": "TBQVMD", "public_name": "Niklas Amberg", "biography": "I am a Data Scientist at REWE Group, using my background in information systems to solve complex problems with data-driven approaches. I am passionate about programming in Python and continuously seek to enhance my skills. Additionally, I am interested in exploring cloud technologies and their applications in the field of data science.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 194, "guid": "c2604d42-c404-581f-a4f5-b1b2cc1ebca5", "logo": "", "date": "2023-09-15T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 2", "slug": "cfp-194-balancing-the-electricity-grid-with-multi-level-forecasting-models", "url": "https://amsterdam2023.pydata.org/cfp/talk/WCMURW/", "title": "Balancing the electricity grid with multi-level forecasting models", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Join us as we explore the complexities of balancing the electricity grid amidst the rise of renewable energy sources. We\u2019ll discover the challenges in forecasting electricity consumption from diverse industrial resources and the modelling techniques employed by Sympower to achieve accurate forecasts. Gain insights into the trade-offs involved in aggregating data at different hierarchical levels in time series forecasting.", "description": "The shift to renewable energy sources presents a major challenge for the electricity grid: solar and wind facilities are constantly varying in power output, making it harder to keep the supply and demand in balance. This creates a need for demand response: strategic activation or deactivation of large industrial resources to balance the electricity grid. Reliable demand response requires an accurate forecast of industrial electricity consumption, to get a clear understanding of which resources can be controlled at what time.\r\n\r\nIn this talk we will discuss the challenges faced when forecasting electricity consumption from industrial resources from different kinds of industries such as furnaces, greenhouses or paper mills. We\u2019ll discuss the different modelling approaches for predicting time series including regression, forecasting and deep learning, and we will discuss the suitability of each in different scenarios. Using the forecasting of electricity consumption of industrial resources as an example, we show how we make our forecasts at Sympower to help balance the electricity grid.\r\n\r\nFinally we will discuss a trade-off in forecasting: Trends and seasonality often only emerge at aggregate levels, making forecasting at the aggregate level easier. On the other hand, business often requires precision-level insights. Aggregate data is inherently less noisy since the errors tend to cancel out, but also might fail to capture lower-level details. We will discuss the considerations to make when forecasting at different aggregated levels in time or across groups, and what you could do to forecast consistently across different aggregate levels.. \r\n\r\nKEY TAKEAWAYS\r\n  - Gain insights into selecting the most suitable modelling technique for your forecasting need\r\n  - Understand the challenges posed by the evolving electricity grid and the significance of demand response\r\n  - Explore the trade-offs involved in aggregating data at different hierarchical or temporal levels in time series forecasting", "recording_license": "", "do_not_record": false, "persons": [{"id": 197, "code": "FY9KF3", "public_name": "Rik van der Vlist", "biography": "Rik is a machine learning engineer with a strong foundation in electrical engineering and a specialization in leveraging electricity data for smart use cases. With previous experience at Eneco, he has focused on delivering automated home energy insights to large group of customers. Currently, Rik is dedicated to constructing a scalable forecasting model for a sustainable electricity grid, combining his passion for data science and sustainable solutions. He thrives on creating value and generating insights from raw data, demonstrating his proficiency in building robust and scalable data pipelines using Spark and Python.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 52, "guid": "7c5cd37a-c881-51b5-ad88-bad2af81cbb7", "logo": "", "date": "2023-09-15T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 2", "slug": "cfp-52-multimodal-product-demand-forecasting-from-pixels-on-your-screen-to-a-meal-on-your-plate", "url": "https://amsterdam2023.pydata.org/cfp/talk/FMR7XK/", "title": "Multimodal Product Demand Forecasting: From pixels on your screen to a meal on your plate", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "The customers of Picnic use images and texts of products to decide if they like our products, so why not include those data streams in our Temporal Fusion Transformers that we use for Product Demand Forecasting?\r\n\r\nJoin us for a thrilling journey through convolutional, graph-based, and transformer-based architectures. Learn about methods to turn images, texts, and geographical information into features for other applications as we did for product demand forecasting. Discover how Picnic Technologies uses state-of-the-art multimodal approaches for demand forecasting to prevent food waste and keep our customers happy!", "description": "Ever wondered how we keep your favorite brand of potato chips in stock, while that exotic sauce is forever \"currently unavailable\"? We'll reveal the secrets behind these mysteries in our talk on how we are using recent advancements in visual, textual, and contextual information processing techniques to optimize our Product Demand Forecasting. Because everybody loves looking at pictures of groceries but prefers having them available and on their doorstep (delivered for free).\r\n\r\nWe begin by shedding light on traditional product demand forecasting - the 'old potatoes' of the industry - and its limitations, like the notorious cold start problem and category dynamics.\r\n\r\nOur talk is a must-watch for data scientists, product managers, supply chain wizards, and anyone who has ever been curious about the new innovations in number-crunching that gets your favorite snack from the factory to your front door. If you're in the e-commerce or retail industries, this talk will be as essential as oatmilk and bread in a shopping list. Don\u2019t worry if words like multimodal, temporal, and fusion sound intimidating; They will be explained in a way that is informative and entertaining if you have seen them before but also if you have not.\r\n\r\nWe promise it\u2019s not all graphs and matrices \u2013 expect an unexpected rollercoaster ride through the aisle of our digital store. With each turn, you'll discover how our multimodal method uses product images, textual descriptions, and additional contextual information to predict if potatoes will overtake pasta in popularity next month. We'll show you the \u2018cart\u2019 loads of data behind these predictions, putting a fun spin on the world of groceries.\r\n\r\nIn the grand finale, we\u2019ll take you behind the scenes of our model's showdown with traditional methods. Spoiler alert: our method doesn\u2019t just predict demand; it leaves the traditional methods looking like overripe bananas in the back of the fridge (which is a bad state for bananas to be in).\r\n\r\nThe main takeaway from our talk - besides a craving for potatoes - will be an understanding of multimodal demand forecasting and how all these different types of data are becoming easier and easier to use for real-world business value. By the end of our talk, you'll be filled with ideas (and the sudden need to do groceries with Picnic, you are our target audience: Loving reliability, good products and you have busy jobs), inspired by the potential of multimodal machine learning in forecasting. So, whether you're a data scientist, product manager, or a curious shopper, come along for an enjoyable trip through the world of groceries and demand forecasting!\r\n\r\nPrepare your shopping list and join us. Just remember, our model may predict the demand for potatoes, but it's still up to you to remember the dip!", "recording_license": "", "do_not_record": false, "persons": [{"id": 66, "code": "JLFTAQ", "public_name": "Maarten Sukel", "biography": "Maarten is a Data Scientist working at Picnic Technologies working mostly on Demand Forecasting and running machine learning at scale. Meanwhile at the University of Amsterdam, he works on research into the use of multimodal approaches for a range of applications.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 220, "guid": "7afe76a0-a34b-5e97-95b5-c3192c87e543", "logo": "", "date": "2023-09-15T13:00:00+02:00", "start": "13:00", "duration": "00:30", "room": "Room 2", "slug": "cfp-220-minimizing-the-data-mesh-mess", "url": "https://amsterdam2023.pydata.org/cfp/talk/G7RBN9/", "title": "Minimizing the Data Mesh Mess", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk delves into the topic of minimizing the Data Mesh mess. We will explore practical strategies and a data platform architecture for effectively governing and managing data within a decentralized data setup. We can balance decentralization and maintaining data quality by imposing a few constraints. The takeaways of this talk are drawn from the data platform at Enza Zaden.", "description": "The concept of Data Mesh has gained significant attention in recent years, offering a promising approach to managing data at scale. However, as organizations embrace the decentralized approach to data, they often encounter unforeseen challenges and potential chaos that can arise within a Data Mesh implementation.\r\n\r\nThis talk delves into the topic of minimizing the Data Mesh mess. We will explore practical strategies and a data platform architecture for effectively governing and managing data within a decentralized data setup. We can balance decentralization with maintaining data quality by imposing a few constraints.\r\n\r\nDuring the session, we will address key questions and considerations such as:\r\n- What constraints can we enforce to increase the quality of shared data while remaining adaptable to the data teams?\r\n- How can we effectively manage data ownership, access controls, and security across diverse data domains?\r\n- What are the recommended approaches for metadata management?\r\n- How can we modify the level of flexibility and ownership for data teams depending on their level of experience and readiness?\r\n\r\nDrawing from a real-world data platform at Enza Zaden (https://www.enzazaden.com/), we will discuss successful strategies and best practices for taming the inherent complexity of a Data Mesh. This talk aims to provide practical insights and actionable steps to help you create a data platform that minimizes the Data Mesh mess.", "recording_license": "", "do_not_record": false, "persons": [{"id": 222, "code": "HVQ89K", "public_name": "Cor Zuurmond", "biography": "Cor improves business processes with data.\r\n\r\nWith a background in physics and an MSc in data science, he is well-versed in various tools and practices. Cor understands, on a fundamental level, the techniques that he applies. He converts questions into automated and optimized processes. Simply put: Cor believes that actions lead to insights more often than insights lead to actions.\r\n\r\nAfter laying out a solid data engineering foundation, Cor applies AI techniques to give every project or product an unrivaled edge. He loves to automate solutions to turn your most daunting business challenges into a walk in the park.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 151, "guid": "31d15b15-0304-58da-91d1-947c6fcb9995", "logo": "", "date": "2023-09-15T14:20:00+02:00", "start": "14:20", "duration": "00:30", "room": "Room 2", "slug": "cfp-151-return-to-data-s-inferno-are-the-7-layers-of-data-testing-hell-still-relevant-", "url": "https://amsterdam2023.pydata.org/cfp/talk/WEEMK9/", "title": "Return to Data's Inferno: are the 7 layers of data testing hell still relevant?", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Back in 2018, a blogpost titled \"Data's Inferno: 7 circles of data testing hell with Airflow\" presented a layered approach to data quality checks in data applications and pipelines. Now, 5 years later, this talk looks back at Data's Inferno and surveys what has changed but also what hasn't in the space of ensuring high data quality.", "description": "5 years ago a blog post called \"Data's Inferno\" (https://medium.com/wbaa/datas-inferno-7-circles-of-data-testing-hell-with-airflow-cef4adff58d8) was written about how to ensure high data quality with Apache Airflow. It suggested using different types of tests as layers to catch issues lurking within the data. These layers included tests for Airflow DAG integrity, mock data pipelines, production data tests, and more. Combining these layers made for a reliable way to filter out incorrect data. Despite the blogpost's age, the ideas are still relevant today. New tools and applications have been developed to help improve data quality as well as new best practices. In this talk, we'll review the layers of Data's Inferno and how they contributed to improving data quality. We'll also look at how new tools address the same concerns. Finally, we'll discuss how we expect and hope the data quality landscape to evolve in the future.", "recording_license": "", "do_not_record": false, "persons": [{"id": 160, "code": "B3JKRL", "public_name": "Daniel van der Ende", "biography": "Daniel van der Ende is a Data Engineer at Xebia Data. He enjoys working on high performance distributed computation with Spark, empowering data scientists by helping them to run their models on very large datasets with high performance. He is an Apache Spark and Apache Airflow contributor and speaker at conferences and meetups.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 71, "guid": "7bf14af7-ada1-5696-86bb-294140a478eb", "logo": "", "date": "2023-09-15T15:20:00+02:00", "start": "15:20", "duration": "00:30", "room": "Room 2", "slug": "cfp-71-import-full-focus-as-ff-how-to-reduce-stress-and-pressure-as-a-data-specialist-", "url": "https://amsterdam2023.pydata.org/cfp/talk/DK83DT/", "title": "import full-focus as ff \u2013 How to reduce stress and pressure as a data specialist.", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Data science, IT and software development become more and more complex and are subject to increasing requirements and fast-paced business demand. Higher complexity, higher pace and higher quality requirements result in more pressure on our fellow data engineers and data scientists. \r\n\r\nMore pressure, but are we resilient enough to withstand that increasing pressure? You have probably already seen its outcome. Unhappiness, stress or even burn-outs of co-workers, instead of creating cool code, great solutions and building a better world using your skills.\r\n\r\nHow to change the pressure and stress you perceive as a data scientist, data engineer of ML-engineer? How to ensure that your brain\u2019s frontal lobe returns to a problem solving and decision-making state?", "description": "**Target audience**\r\nAll experience levels data engineers, data scientists and analysts. For those who start hitting do\u2019s, don\u2019ts and other hard walls in real life companies and projects. Especially if you experience a drain of energy and focus from those pressure and constrains. Senior or junior, there is much to learn and experience.\r\n\r\n**Takeaway**\r\nLearn and experience 3 great tools to change your resilience instantly and consistently towards pressure and stress. Not just for yourself, but also be able to see and assist co-workers, family, or other loved ones if they experience stress. \r\n\r\n**Background knowledge needed**\r\nNone. Just be sure to bring both your head and body to this workshop to experience how quickly these tools work for you. \r\n\r\n**Time**\r\n\u2022\t 0 \u2013 5 Intro and experience tool #1\r\n\u2022\t 5 \u2013 15 Control your nervous system and work-related stress\r\n\u2022\t15 \u2013 20 experience tool #2\r\n\u2022\t20 \u2013 25 Your stress and social states (based on polyvagal theory)\r\n\u2022\t25 \u2013 30 experience tool #3", "recording_license": "", "do_not_record": false, "persons": [{"id": 89, "code": "EZHFKR", "public_name": "Maarten Oude Rikmanspoel", "biography": "I love working with both technology and people. Currently working as a freelance data engineer and business intelligence specialist to satisfy the tech part of my heart. Fell in love with Python and the PyData modules in 2017 after unsuccessful relationships with Java and C++ in the past. Applying this in a variety of industries and companies.\r\n\r\nIn parallel, I\u2019m creating CalmCode.nl for the past 1,5 years with the aim of guiding software developers, IT- and data specialists towards less stress and burnouts. I\u2019ve seen to many bad examples in the larger companies and multi-nationals where developers almost looked as being oppressed instead of being able to do their work properly and in a nice environment. So the people-oriented part of my heart get\u2019s fuelled when I see people grow and being able to take control of their lives again.\r\n\r\n\u201cWe\u2019re all just walking each other home.\u201d Ram Dass", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 3": [{"id": 268, "guid": "e8e06482-a55b-5837-adc3-f7bc91be7eb0", "logo": "", "date": "2023-09-15T09:00:00+02:00", "start": "09:00", "duration": "00:50", "room": "Room 3", "slug": "cfp-268-keynote-katharine-jarmul", "url": "https://amsterdam2023.pydata.org/cfp/talk/LZMCLL/", "title": "Keynote Katharine Jarmul", "subtitle": "", "track": null, "type": "Keynote", "language": "en", "abstract": "Lorem ipsum dolor", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [{"id": 282, "code": "97AAL9", "public_name": "Katharine Jarmul", "biography": "Katharine Jarmul is a privacy activist and data scientist whose work and research focuses on privacy and security in data science workflows. She recently authored Practical Data Privacy for O'Reilly and works as a Principal Data Scientist at Thoughtworks. Katharine has held numerous leadership and independent contributor roles at large companies and startups in the US and Germany -- implementing data processing and machine learning systems with privacy and security built in and developing forward-looking, privacy-first data strategy.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 3, "guid": "3c7480aa-cb34-5f97-bc1a-af7186c3eadb", "logo": "", "date": "2023-09-15T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 3", "slug": "cfp-3-personalization-at-uber-scale-via-causal-driven-machine-learning", "url": "https://amsterdam2023.pydata.org/cfp/talk/D9VMSK/", "title": "Personalization at Uber scale via causal-driven machine learning", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In this talk, we outline how we introduced causality into our machine learning models within the core checkout and onboarding experiences globally, thereby strongly improving our key business metrics. We discuss case studies, where experimental data were combined with machine learning in order to create value for our users and personalize their experiences, and we share our lessons learned with the goal to inspire attendees to start incorporating causality into their machine learning solutions. Additionally, we explain how the open source Python package developed at Uber, CausalML, can help others in successfully making the transition from correlation-driven machine learning to causal-driven machine learning.", "description": "In this talk, we outline how we introduced causality into our machine learning models within the core checkout and onboarding experiences globally, thereby strongly improving our key business metrics. We discuss case studies, where experimental data were combined with machine learning in order to create value for our users and personalize their experiences, and we share our lessons learned with the goal to inspire attendees to start incorporating causality into their machine learning solutions. Additionally, we explain how the open source Python package developed at Uber, CausalML, can help others in successfully making the transition from correlation-driven machine learning to causal-driven machine learning.", "recording_license": "", "do_not_record": false, "persons": [{"id": 14, "code": "TWXPR7", "public_name": "Okke van der Wal", "biography": "Leading the Payments Machine Learning team at Uber working on Anomaly Detection, Personalization & Fraud Detection within the Onboarding and Checkout experiences at Uber using Contextual Bandits, Uplift Modelling & Reinforcement Learning.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 255, "guid": "4a325da5-4ccc-5d5d-ab16-858cd62b8c87", "logo": "", "date": "2023-09-15T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 3", "slug": "cfp-255-mlops-on-the-fly-optimizing-a-feature-store-with-duckdb-and-arrowflight", "url": "https://amsterdam2023.pydata.org/cfp/talk/L3WFCW/", "title": "MLOps on the fly: Optimizing a feature store with DuckDB and ArrowFlight", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Feature Stores are a vital part of the MLOps stack for managing machine learning features and ensuring data consistency. This talk introduces Feature Stores and the underlying data management architecture. We\u2019ll then discuss the challenges and learnings of integrating DuckDB and Arrow Flight into the our Feature Store platform, and share benchmarks showing up to 30x speedups compared to Spark/Hive. Discover how DuckDB and ArrowFlight can also speedup your data management and machine learning pipelines.", "description": "In this talk, we will cover the following topics:\r\n\r\n\u2022\tIntroduction to Machine Learning Feature Stores (5 min): Understanding the role of feature stores in the MLOps stack and their significance in managing machine learning features within organizations.\r\n\u2022\tData management architecture behind Feature Stores (2-3 min): Exploring the underlying mechanisms and data management components employed in feature stores.\r\n\u2022\tIntroduction to DuckDB and Arrow Flight (5 min): Highlighting the integration of DuckDB and Arrow Flight into the PyData ecosystem, leveraging the capabilities of Arrow.\r\n\u2022\tThe journey of integrating DuckDB and Arrow Flight into our Feature Store platform (12 min): Sharing our experiences and insights on integrating DuckDB and Arrow Flight into the Hudi-based Lakehouse platform that powers our (offline) feature store, discussing challenges and successes encountered along the way.\r\n\u2022\tBenchmarks (5 min): Presenting a benchmark comparing the performance of DuckDB/Arrow Flight vs Spark/HiveServer2, in particular for small to medium sized data.\r\n\r\nAttendees will gain a deeper understanding of feature stores, insights into the integration of DuckDB and ArrowFlight into the PyData ecosystem, and practical knowledge on enhancing the performance of machine learning pipelines.", "recording_license": "", "do_not_record": false, "persons": [{"id": 300, "code": "JXJ7H8", "public_name": "Fabio Buso", "biography": "Fabio Buso is VP of Engineering at Hopsworks, leading the Feature Store development team. Fabio holds a master\u2019s degree in Cloud Computing and Services with a focus on data intensive applications.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 282, "guid": "e5be9c09-4c7c-5a3f-b1f8-2c7ecec74cd8", "logo": "", "date": "2023-09-15T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 3", "slug": "cfp-282-the-proof-of-the-pudding-is-in-the-way-of-eating-quasi-experimental-methods-of-causal-inference-and-their-practical-pitfalls", "url": "https://amsterdam2023.pydata.org/cfp/talk/7CN8JC/", "title": "The proof of the pudding is in the (way of) eating: quasi-experimental methods of causal inference and their practical pitfalls", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Data scientists and analysts are using quasi-experimental methods to make recommendations based on causality instead of randomized control trials. While these methods are easy to use, their assumptions can be complex to explain. This talk will explain these assumptions for data scientists and analysts without in-depth training of causal inference so they can use and explain these methods more confidently to change people's minds using data.", "description": "Instead of relying solely on randomized control trials (also known as A/B tests), which are considered the gold standard for inferring causality, data scientists and analysts are increasingly turning to quasi-experimental methods to make recommendations based on causality. These methods, including open-source libraries such as CausalImpact (originally an R package but with numerous Python ports), are easy to use, but their assumptions can be complex to explain. I will break down these assumptions and explain how they can help practitioners determine when to use these methods (and when not to use them), using examples from the world of digital language learning. The key takeaway is that when it comes to changing people's minds using data, explaining assumptions to decision-makers is just as important as understanding the underlying statistics.\r\n\r\n**Outline**\r\n- Minute 0-5: Introduction and Motivation\r\n- Minute 5-10: Difference-in-Difference / Bayesian Structural Time-Series\r\n- Minute 10-15: Case - Conversion effects of content changes based language-pair specific releases at Babbel\r\n- Minute 15-20: Regression Discontinuity Design\r\n- Minute 20-25: Case - Estimating motivational effects of language assessment\r\n- Minute 25-30: Wrap-up / Take-Aways\r\n\r\nAttendees should have basic knowledge of statistics and causality to get the most out of this talk.", "recording_license": "", "do_not_record": false, "persons": [{"id": 284, "code": "MQT9LH", "public_name": "Jakob Willisch", "biography": "As Head of Product Data at Babbel, I lead data-scientists, analysts and engineers to improve decision-making of people and machines. Before joining Babbel I did quantitative research in Political Science and Political Economy.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 119, "guid": "ac0cd2f6-d8ea-5e5f-8cec-57631b7fc9c8", "logo": "", "date": "2023-09-15T13:00:00+02:00", "start": "13:00", "duration": "00:30", "room": "Room 3", "slug": "cfp-119-ok-doomer", "url": "https://amsterdam2023.pydata.org/cfp/talk/3L39SY/", "title": "Ok, doomer", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "AI won't end the world, but it can and is making life miserable for plenty of folks. Instead of engaging with the AI overlords, let's explore a pragmatic set of design choices that all Data Scientists and ML devs can implement right now, to reduce the risks of deploying AI systems in the real world.", "description": "Leave the AI boomers to grumble amongst themselves about x-risk and the singularity. Instead let's focus-in on how we can alleviate the real-world harms happening right now.\r\n\r\nToo often attempts to identify risks and respond to failure modes of ML and automated systems dive straight into the specifics of model, stack, and implementation. Or worse, add further impenetrable layers of abstraction - the \"more models, more problems\" syndrome.  While it's encouraging to see the ecosystem of explainability tools and ML ops surging, as developers and pragmatists we should always prefer the simplest and cheapest tool in our toolkit which is fit for purpose. \r\n\r\nThis talk calls attention to a number of existing simple, cheap and effective levers for flagging and reducing risk that are often overlooked. \r\n\r\nThese are software design fundamentals like timely and contextual feedback loops, or graceful degradation, that are easily forgotten in the rush to market. These pragmatic tools and product design choices can immediately improve visibility, safety and reduce reputational risk for any team implementing AI.\r\n\r\nP.S. Better oversight and tooling for our current tech will, by definition, improve our chances of being alerted if an existentially risky intelligence did happen to emerge from the silicon ether, one day. So it's a win win, really. \ud83e\udd37\u200d\u2640\ufe0f", "recording_license": "", "do_not_record": false, "persons": [{"id": 142, "code": "CQQKWZ", "public_name": "Laura Summers", "biography": "Laura is a Design Engineer and Prodigy Teams Product Lead at Explosion AI. \r\n\r\nShe is the founder of Debias AI, (debias.ai) and the human behind Sweet Summer Child Score (summerchild.dev),  Ethics Litmus Tests (ethical-litmus.site), fairXiv (fairxiv.org), the Melbourne Fair ML reading group (groups.io/g/fair-ml). Laura is passionate about feminism, digital rights and designing for privacy. She speaks, writes and runs workshops at the intersection of design and technology.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 142, "guid": "9d38c367-284b-546b-ab29-f5fb5089392d", "logo": "", "date": "2023-09-15T13:40:00+02:00", "start": "13:40", "duration": "00:30", "room": "Room 3", "slug": "cfp-142-llm-agents-101-how-i-gave-chatgpt-access-to-my-to-do-list", "url": "https://amsterdam2023.pydata.org/cfp/talk/N7Y7X7/", "title": "LLM Agents 101: How I Gave ChatGPT Access to My To-Do List", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "ChatGPT is a fantastic assistant, but it cannot do everything yet. For example, it cannot automatically manage my calendar, update my to-do list, or do anything that requires it to perform actions. However, what would it take to make this reality? I decided to put it to the test by allowing ChatGPT to manage my to-do list for me.\r\n\r\nDuring this presentation, I will first introduce you to the concepts of LLM-based agents and how they work. After this introduction, I will demo my agent-based to-do list manager. After this demo, we will dive into the implementation challenges, such as handling hallucinations, parsing actions, etc. I discovered some very clever engineering solutions and tricks to solve these problems, which I will share with you. By the end of the presentation, you will know how LLM-based agents work, how well they work, when they do not, and how to start implementing them yourself.\r\n\r\nThis talk is for people who want to learn how to build their first LLM-based agent. Familiarity with Python, PyDantic, and LMMs is nice during this presentation but not essential. As long as you love overengineered solutions to a basic to-do list, you will like this presentation.", "description": "ChatGPT is a fantastic assistant, but it cannot do anything that requires it to perform actions. In this talk, we explore how we can solve this issue with LLM-based agents. I will cover topics such as:\r\n- A basic introduction to LLMs and the OpenAI API\r\n- An overview of LLM agents, the REACT framework, and tools.\r\n- A demonstration of an agent I built to manage my to-do list.\r\n- A discussion on implementation challenges, such as handling hallucinations, parsing actions, adhering to formatting rules, and managing apologetic LLMs.\r\n- Ingenious solutions and tricks for overcoming these challenges, like using JSON schema to describe formatting rules, designing effective tools, and how to enable the agent to fix its own mistakes. We'll showcase these solutions through amusing moments and challenges encountered during the development of my to-do list agent.\r\n- A summary of what works well and what still needs improvement\r\n\r\nThis talk is designed as an introduction to LLM agents. Throughout the presentation, I will aim to maintain a high-level perspective to ensure that even less technical audience members can grasp the concepts. To achieve this, I will share entertaining situations where my agent did something unexpected and how I resolved those issues. However, the presentation will still be practical enough for technical people to know all the concepts and techniques to develop their LLM agents.", "recording_license": "", "do_not_record": false, "persons": [{"id": 136, "code": "DNEQMW", "public_name": "Jordi Smit", "biography": "Hi! My name is Jordi Smit. I\u2019m deeply passionate about software engineering, data science, and automation. Nothing makes me happier than creating software that helps humans by automating a tedious and manual-intensive part of their job. Therefore, I love talking about data science since this field has opened the door to many new kinds of automations. However, too often, data science solutions stay stuck at the proof of concept level. To combat this issue, you also need software engineering knowledge. That is why I love the intersection between software engineering, data science, and automation.\r\n\r\nCurrently, I work as a Machine Learning Engineer at GoDataDriven in Amsterdam. Here I help companies to transform their ML-based models into production-ready applications. I love this job because it allows me to explore the intersection between software engineering and data science daily.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 244, "guid": "4fd749c4-0c64-50f5-be8d-498d1ea5e0ea", "logo": "", "date": "2023-09-15T14:20:00+02:00", "start": "14:20", "duration": "00:30", "room": "Room 3", "slug": "cfp-244-fine-tuning-with-finesse-tuning-llms-with-well-curated-training-data", "url": "https://amsterdam2023.pydata.org/cfp/talk/G9HSRK/", "title": "Fine-tuning with Finesse: Tuning LLMs with Well-curated Training Data", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "The continued success of large language models (LLMs) hinges upon accurate, diverse, and well-labeled data. However, getting this data with the right context provides another set of challenges. \r\n\r\nThis talk will explore how to facilitate a data-centric workflow for LLM development. We\u2019ll cover the importance of data annotation, the process of developing and curating your data pipeline, a four-step workflow to generate your own fine-tuned LLM, and the pros and cons of this approach. Lastly, we\u2019ll cover the importance of continuous learning and how to future-proof your newly generated fine-tuned LLM, emphasizing speed and observability. If you\u2019re curious about the next wave of generative AI and how to make the most of it through well-curated, context-specific data, this talk is for you.", "description": "In this presentation, machine learning enthusiasts, data scientists, and the generative AI curious will explore how to leverage the latest advancements in large language models (LLMs) for context-specific use cases. With all of the recent developments and rapid advancements around generative AI, it\u2019s important to separate the signal from the noise by demonstrating the value that these generative models can bring, especially when they\u2019re fine-tuned to specific parameters or datasets with specific use cases. \r\n\r\nThis talk is an informative, guided exploration of not only why it\u2019s important to build a data-centric workflow for LLMs, but how exactly to do so and the multitude of tools that are out there that make this more accessible than ever. Featuring seasoned experts in the field of open source machine learning and data science, this talk will not only explain how it works but inspire curiosity in a hands-on manner, leaving attendees with open-source resources to test out this workflow in an accessible manner (through a CoLab notebook to be exact). \r\n\r\nWe\u2019ll set the stage by providing context; sharing why a data-centric approach is essential when fine-tuning and finessing LLMs. Next, we\u2019ll share what a data-centric workflow looks like and the tools and resources used to develop it. Once the stage has been set, we\u2019ll start to cover how to begin the fine-tuning process. \r\n\r\nAttendees will be walked through a guided tour of how exactly to fine-tune LLMs with finesse through well-curated training data. We\u2019ll start by breaking down the four stages of learning, where each stage strategically and mindfully injects human signals, converging the model to perform to the specific use case provided. In each of these steps, we\u2019ll center the conversation around the tools and tactics used and the importance of context and curation when it comes to the datasets employed. We\u2019ll also break down the Parameter-Efficient FineTuning (PEFT) approach, which makes this work executable on such large foundational models.\r\n\r\nAs the training walkthrough ends, we\u2019ll wrap up the conversation and demonstration by sharing just how to improve efficiency for the long haul by highlighting the importance of continuous learning. We\u2019ll offer a brief walkthrough of how continuous model fine-tuning works and how to make the most of it for the long haul. This includes a quick discussion on how to enable continuous model fine-tuning with an emphasis on speed and observability. \r\n\r\nThe talk will conclude with links and resources to inspire further exploration and curiosity. Attendees will leave with a deeper understanding of how exactly to leverage these tools and materials, and resources to make the most of them.  This includes a notebook with a guided tutorial and demonstration and additional links and references used to develop this workflow. Our goal is to ensure attendees are informed and empowered with the skills and resources to make the most of their learning after this demonstration. \r\n\r\nOutline of Time: 30 minute talk\r\n\r\n12 minutes: \r\n- Introduction of topic and technology\r\n- Introduction of the problems that this solves in the industry\r\n- Importance of data-centric model retraining\r\n- Tools and techniques used\r\n - Theoretical walkthrough \r\n10 minutes: \r\n- Technical demonstration and walkthrough\r\n5 minutes: \r\n- Factors to consider when fine-tuning LLMs\r\n- Continuous learning and deployment\r\n3 minutes: \r\n- Wrap up and additional time for buffer\r\n- Share where to find resources and references to continue curiosity.\r\n\r\nCore takeaways: \r\nWhy does a datacentric workflow for fine-tuning LLMs matter? \r\nWhat goes into building a datacentric workflow for fine-tuning foundational models?\r\nHow to build and maintain a datacentric workflow for foundational model retraining.\r\nWhat core steps are important when fine-tuning foundational models?\r\nWhy is context and human signal important to consider when fine-tuning LLMs?\r\nHow to build a sustainable, continuous learning workflow.", "recording_license": "", "do_not_record": false, "persons": [{"id": 236, "code": "G8JHPR", "public_name": "Erin Mikail Staples", "biography": "Erin Mikail Staples is a very online individual passionate about facilitating better connections online and off. She\u2019s forever thinking about how we can communicate, educate and elevate others through collaborative experiences.\r\n\r\nCurrently, Erin is a Senior Developer Community Advocate at Label Studio. At Label Studio \u2014 she empowers the open source community through education and advocacy efforts. Outside of her day job, Erin is a comedian, graduate technical advisor, content creator, triathlete, avid reader, and dog parent.\r\n\r\nMost importantly, she believes in the power of being unabashedly \"into things\" and works to help friends, strangers, colleagues, community builders, students, and whoever else might cross her path find their thing.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 266, "guid": "63aa42ea-2fc6-5bfb-92ac-11e83a7f45f8", "logo": "", "date": "2023-09-15T16:00:00+02:00", "start": "16:00", "duration": "00:50", "room": "Room 3", "slug": "cfp-266-keynote-thomas-wolf", "url": "https://amsterdam2023.pydata.org/cfp/talk/K9PMGM/", "title": "Keynote Thomas Wolf", "subtitle": "", "track": null, "type": "Keynote", "language": "en", "abstract": "Keynote by Thomas Wolf. He will be accompanied on stage by Alessandro Cappelli, Julien Launay & Guilherme Penedo, all members of the Hugging Face team in Amsterdam working on large model training.", "description": "Lorum ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [{"id": 278, "code": "8YM3SF", "public_name": "Thomas Wolf", "biography": "Thomas Wolf is a co-founder and Chief Science Officer at Hugging Face. He is passionate about creating open-source software that makes complex research accessible, and most proud of creating the Transformers and Datasets libraries as well as the Magic-Sand tool. When he\u2019s not building OSS, he pushes for open-science in research in AI/ML, trying to lower the gap between academia and industrial labs. His current research interests are centered around overcoming the current limitations of LLMs with multi-modalities and complementary approaches.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Tutorial Room": [{"id": 259, "guid": "d9ad798a-cb3b-5209-9d45-7cef2617937f", "logo": "", "date": "2023-09-15T10:00:00+02:00", "start": "10:00", "duration": "01:20", "room": "Tutorial Room", "slug": "cfp-259-unlocking-the-black-box-a-practical-guide-to-finding-an-alibi-for-machine-learning-models", "url": "https://amsterdam2023.pydata.org/cfp/talk/J7FT8T/", "title": "Unlocking the Black Box: A practical guide to finding an alibi for machine learning models", "subtitle": "", "track": null, "type": "Tutorial__", "language": "en", "abstract": "Knowledge work is undergoing a transformative journey with machine learning (ML) but the interpretability of the models we interact with is still lagging behind the coolness and hype of the technologies using ML. This workshop seeks to address the gap between the speed at which we use and adopt ML and the pace at which we understand it. During the workshop, we will cover fundamental concepts and techniques of interpretable machine learning, and explore various explainability methods supported by the Alibi Explain library so that you can get started explaining your models. If you've been meaning to dive deeper into the field of interpretable ML, add interpretability to your workflows, find an alibi for your models, or are simply curious about the field, come and join us for a fun 90-minute interactive session on interpretable ML.", "description": "In the era of complex and powerful machine learning (ML) models, understanding the decision-making process of these models has become a challenge, and different interpretability methods can help us build trust, address bias, and ensure compliance with different standards. The Alibi Explain library offers a comprehensive toolkit for interpreting machine learning models and shedding light on their inner workings. No prior experience with the library is required, but some knowledge of machine learning is expected.\r\n\r\nDuring the workshop, we will cover the fundamental concepts and techniques of interpretable machine learning, exploring various explainability methods supported by Alibi Explain. We will discuss strategies such as rule-based explanations, feature importance, and counterfactual explanations. Through hands-on exercises, participants will gain practical experience in interpreting models and understanding their predictions.\r\n\r\nThroughout the workshop, we will emphasize real-world applications and use cases to demonstrate the relevance and importance of interpretable machine learning. We will discuss how interpretability can enable better decision-making in finance, healthcare, and retail domains. By the end of the workshop, attendees will have a good understanding of interpretable machine learning concepts and practical skills for finding an alibi for their ML models.", "recording_license": "", "do_not_record": false, "persons": [{"id": 249, "code": "LHCXR7", "public_name": "Ramon Perez", "biography": "Hello! I'm Ramon, a data scientist, researcher, and educator living in Sydney. I currently work as a freelance data professional and was previously a Senior Product Developer at Decoded, a technology education company based in the UK. While at Decoded, I created custom data science tools, workshops, and training programs for clients in industries ranging from retail to finance. Prior to that, I held roles at the intersection of education, data science, and research in the areas of entrepreneurship and strategy, alongside a few ventures in consumer behavior and development economics research in industry and academia, respectively. On the personal side, I enjoy giving talks and technical workshops and have had the privilege of participating in several conferences such PyCon, SciPy, PyData, and countless meetup events. In my spare time, I spend as much time as possible mountain biking and exploring many of the outdoor wonders Australia has to offer.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 189, "guid": "f71f1eae-c12e-5b4f-8902-b8d0b8a38d72", "logo": "/media/cfp/submissions/JMZP3J/00001-3191577244_cHKHVTN.png", "date": "2023-09-15T11:30:00+02:00", "start": "11:30", "duration": "01:00", "room": "Tutorial Room", "slug": "cfp-189-building-a-personal-search-engine-with-llama-index", "url": "https://amsterdam2023.pydata.org/cfp/talk/JMZP3J/", "title": "Building a personal search engine with llama-index", "subtitle": "", "track": null, "type": "Tutorial_", "language": "en", "abstract": "Wouldn\u2019t it be great to have a Google-like search engine, but then for your own text files and completely private? In this tutorial we\u2019ll build a small personal search engine using open source library llama-index.", "description": "In this tutorial we will build a small personal search engine using open source library `llama-index`. Llama-index provides utility functions for ingesting various kinds of data, breaking the data up in chunks, building an index of that data using vector embeddings, and retrieving data from the index based on queries. We can even use llama-index to post-process the retrieval results for us using large language models such as GPT.\r\n\r\nThe target audience is people that are already familiar with Python. Participants will experience working with unstructured data, vector embeddings, and explore the possibilities of the recent developments in natural language processing. \r\n\r\nWorkshop materials will be provided via Github before the start of the workshop. For the demo application, we will only use open-source software and models that are light enough to run on an average laptop without a GPU. \r\nUsing llama-index with OpenAI\u2019s API is optional. If you want to explore postprocessing your results with GPT-3.5, we recommend registering an OpenAI account and making sure you have your OpenAI API key ready.", "recording_license": "", "do_not_record": false, "persons": [{"id": 93, "code": "7GVX7B", "public_name": "Judith van Stegeren", "biography": "Judith van Stegeren is a researcher, engineer and consultant. Together with Yorick van Pelt, she runs Datakami, a consulting firm specialized in large language models.\r\n\r\nPreviously, she worked as a machine learning engineer at Floryn, a Dutch fintech startup that finances small and medium businesses. Before that, she researched text generation at the University of Twente and worked as an information security specialist at the Dutch National Cyber Security Centre in the Hague.\r\n\r\nJudith holds a PhD in computer science from the University of Twente. Her interests include investing, natural language processing, procedural art and video games.", "answers": []}, {"id": 188, "code": "MYPW3S", "public_name": "Yorick van Pelt", "biography": "Yorick is a consultant at Datakami doing generative AI for finance&creativity. He also has years of experience consulting in data science, ops and functional programming.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 108, "guid": "66510cf5-c4a9-5cf2-94c1-863495919590", "logo": "", "date": "2023-09-15T13:00:00+02:00", "start": "13:00", "duration": "01:30", "room": "Tutorial Room", "slug": "cfp-108-mastering-knowledge-graph-modeling-with-neo4j-a-practical-tutorial", "url": "https://amsterdam2023.pydata.org/cfp/talk/MV7H7N/", "title": "Mastering Knowledge Graph Modeling with Neo4j: A Practical Tutorial", "subtitle": "", "track": null, "type": "Tutorial", "language": "en", "abstract": "This hands-on tutorial introduces participants to knowledge graph modeling using Neo4j, a popular graph database. Suitable for beginners and those seeking to enhance their knowledge, the tutorial will help attendees to learn the fundamentals of knowledge graphs, gain insights into Neo4j's modeling capabilities, and acquire practical skills in designing effective knowledge graph models.", "description": "In this tutorial, we'll explore knowledge graphs and their modeling using Neo4j, a popular graph database. Participants will learn effective modeling techniques and how to leverage this technology for their own projects. \r\n\r\nThe tutorial is for data professionals, data scientists, software engineers, and anyone interested in knowledge graphs. No prior experience with Neo4j or knowledge graph modeling is required, making it suitable for beginners and those looking to expand their knowledge.\r\n\r\nThe tutorial will be interactive, combining theory and practical exercises to provide a comprehensive understanding of knowledge graph modeling. The tone will be informative and engaging, encouraging active learning and collaboration.\r\n\r\nBy the end of this tutorial, participants will:\r\n\r\n1. Understand the concept of knowledge graphs and their significance in representing complex relationships and interconnected data.\r\n2. Gain familiarity with Neo4j and its capabilities for knowledge graph modeling.\r\n3. Acquire knowledge of representation patterns, best practices, pitfalls to avoid, and trade-offs to consider when modeling knowledge graphs.\r\n4. Develop practical skills through hands-on exercises and examples, enabling them to apply knowledge graph modeling techniques to their own projects.\r\n\r\nTentative schedule:\r\n\r\n1. Introduction to Knowledge Graphs (20 minutes)\r\n   - Definition and real-world applications of knowledge graphs\r\n   - General and common knowledge graph elements\r\n\r\n2. Introduction to Neo4j (15 minutes)\r\n   - Overview of Neo4j as a graph database\r\n   - Understanding Neo4J\u2019s graph data model and the Cypher language\r\n\r\n3. Representing knowledge graphs in Neo4J (20 minutes)\r\n   - Understanding different patterns for modeling entities, relations and other knowledge graph elements\r\n   - Choosing the appropriate pattern based on data and application requirements\r\n   - Avoiding common mistakes and pitfalls\r\n   - Making informed decisions about common dilemmas and trade-offs\r\n\r\n4. Hands-on Exercise (20 minutes)\r\n   - Guided exercise to model a knowledge graph using Neo4j\r\n\r\n5. Q&A and Discussion (10 minutes)\r\n   - Addressing participant questions and engaging in interactive discussion\r\n\r\n6. Wrap-up and Conclusion (5 minutes)\r\n   - Recap of key concepts and takeaways from the tutorial\r\n   - Suggestions for further learning and resources\r\n\r\nAll materials, including code examples, exercises, and supplementary resources, will be made available through a dedicated GitHub repository. Participants can access and download these materials to continue their learning journey beyond the tutorial session.", "recording_license": "", "do_not_record": false, "persons": [{"id": 50, "code": "ANRCLH", "public_name": "Panos Alexopoulos", "biography": "Panos Alexopoulos has been working since 2006 at the intersection of data, semantics, and software, contributing to building intelligent systems that deliver value to business and society. Born and raised in Athens, Greece, he currently works as Head of Ontology at Textkernel, in Amsterdam, Netherlands, where he leads a team of Data Professionals in developing and delivering a large cross-lingual Knowledge Graph in the HR and Recruitment domain. \r\n\r\nPanos holds a PhD in Knowledge Engineering and Management from National Technical University of Athens, and has published more than 60 papers at international conferences, journals and books. He is the author of the book \"Semantic Modeling for Data - Avoiding Pitfalls and Breaking Dilemmas\" (O'Reilly, 2020), and a regular speaker and trainer in both academic and industry venues.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 278, "guid": "3b32bca8-108d-5c64-9dd4-d577b0d284f6", "logo": "", "date": "2023-09-15T14:40:00+02:00", "start": "14:40", "duration": "00:30", "room": "Tutorial Room", "slug": "cfp-278-unconference-1", "url": "https://amsterdam2023.pydata.org/cfp/talk/Z87VRP/", "title": "Unconference #1", "subtitle": "", "track": null, "type": "Unconference", "language": "en", "abstract": "Lorem ipsum dolor", "description": "1143", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}, {"id": 281, "guid": "89243294-cdfa-57b6-a06f-a150fc1b56b7", "logo": "", "date": "2023-09-15T15:20:00+02:00", "start": "15:20", "duration": "00:30", "room": "Tutorial Room", "slug": "cfp-281-unconference-4", "url": "https://amsterdam2023.pydata.org/cfp/talk/HB8BKV/", "title": "Unconference #4", "subtitle": "", "track": null, "type": "Unconference", "language": "en", "abstract": "Lorem ipsum dolor", "description": "Lorem ipsum dolor", "recording_license": "", "do_not_record": false, "persons": [], "links": [], "attachments": [], "answers": []}]}}, {"index": 3, "date": "2023-09-16", "day_start": "2023-09-16T04:00:00+02:00", "day_end": "2023-09-17T03:59:00+02:00", "rooms": {"Room 1": [{"id": 47, "guid": "791c9c2c-69d2-5f10-bf2f-707ed3992b42", "logo": "", "date": "2023-09-16T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 1", "slug": "cfp-47-distillation-unleashed-domain-knowledge-transfer-with-compact-neural-networks", "url": "https://amsterdam2023.pydata.org/cfp/talk/3JEKJZ/", "title": "Distillation Unleashed: Domain Knowledge Transfer with Compact Neural Networks", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk explores distillation learning, a powerful technique for compressing and transferring knowledge from larger neural networks to smaller, more efficient ones. It delves into its core components and various applications such as model compression and transfer learning. The speaker aims to simplify the topic for all audiences and provides implementation, demonstrating how to apply distillation learning in real scenarios. Attendees will gain insights into developing efficient neural networks by reviewing the various examples of the complex model. The material will be accessible online for convenient access and understanding.", "description": "As the field of artificial intelligence continues to advance, the demand for more efficient and compact neural network models has become increasingly vital. The ability to compress and transfer knowledge from larger, complex models to smaller, more efficient models has emerged as a powerful solution. In this talk, we aim to shed light on the significance of distillation learning and its applications across various domains.\r\n\r\nIn an era where data sizes and computational requirements are escalating, distillation learning provides a compelling solution to address the challenges posed by these factors. By utilizing a teacher-student framework, this approach facilitates the transfer of knowledge from a larger, well-performing teacher model to a smaller student model. The student model is trained to mimic the behaviour and output of the teacher model, thereby inheriting its expertise. This process enables the creation of compact models that are not only efficient in terms of memory and inference speed but also capable of performing tasks with comparable proficiency. Distillation learning represents a breakthrough in model compression and transfer learning, revolutionizing the field of artificial intelligence and novel machine learning utilising deep neural networks.\r\n\r\nIn this talk, we will provide a comprehensive overview of distillation learning, covering its core components. We will explore the definition and motivation behind, highlighting the role of the teacher model in guiding the student model and the objective of the student model to replicate the teacher model's output. Additionally, we will discuss the diverse applications, including model compression, transfer learning, ensemble learning, multi-task learning, and language models. We will also delve into different types of this learning approach, such as model distillation, knowledge distillation, multi-task distillation, and transfer distillation.\r\n\r\nThis talk facilitates knowledge exchange and inspires the development of efficient neural networks. The speaker simplifies the topic, making it accessible to all audiences. Simple practical implementation in TensorFlow will be demonstrated, showcasing how attendees can apply this technique in real scenarios. No expertise in complex models is required, and the material will be shared online for convenient access and comprehension.\r\n\r\nHighlighted References:\r\n- Mirzadeh, S., Farajtabar, M., Liang, D., & Ghasemzadeh, H. (2020). Improved knowledge distillation via teacher assistant: Bridging the gap between student and teacher. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\r\n- Radosavovic, I., Kosaraju, R. P., Girshick, R., He, K., & Doll\u00e1r, P. (2020). Designing network design spaces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.\r\n- Malik, Shaiq Munir, et al. (2021) Teacher-Class Network: A Neural Network Compression Mechanism. In Proceedings of the British Machine Vision Conference.", "recording_license": "", "do_not_record": false, "persons": [{"id": 60, "code": "Z8XYZT", "public_name": "Hadi Abdi Khojasteh", "biography": "Hadi is an R&D senior machine learning engineer at the Deltatre group, where he is an integral member of the innovation lab and a fellow at the Sport Experiences unit, based in Czechia and Italy. With a solid academic background, Hadi is a former lecturer at the Institute for Advanced Studies in Basic Sciences (IASBS) in Iran and as a researcher at the Institute of Formal and Applied Linguistics (\u00daFAL) at Charles University in Prague. Throughout his career, he has actively participated in numerous industrial projects, collaborating closely with renowned experts in the fields of CV/NLP/HLT/CL/ML/DL. His research focuses on multimodal learning inspired by neural models that are both linguistically motivated and tailored to language and vision, visual reasoning and deep learning. His main research interests are Machine Learning, Deep Learning, Computer Vision, Multimodal Learning and Visual Reasoning while he is experienced in a wide variety of international projects on cutting-edge technologies.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 232, "guid": "d6fbbf46-8263-5421-80ae-34972cf15788", "logo": "", "date": "2023-09-16T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 1", "slug": "cfp-232-data-contracts-in-action-powered-by-python-open-source-ecosystem", "url": "https://amsterdam2023.pydata.org/cfp/talk/3HXFMG/", "title": "Data Contracts in action powered by Python open source ecosystem", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This informative talk aims to close the gap between the theory of data contracts and their real-life implementations. It contains a few Python code snippets and is aimed primarily at data and software engineers. However, it could be food for thought for machine learning engineers, data scientists, and other data consumers.", "description": "Topic: There are a lot of ongoing discussions happening about data contracts. I would like to share with you some lessons learned from data contract implementations and show you some Python examples.\r\n\r\nAudience: data and software engineers; potentially could be interesting for machine learning engineers, data scientists, and other data consumers. Some affinity with Pandas, Great Expectations, and Open Table Formats are desirable. \r\n\r\nType: Informative with some hands-on examples\r\n\r\nMain takeaways:\r\n- better understanding of the data contracts concept \r\n- tips for batch data contracts implementations\r\n- tips for streaming data contracts implementations", "recording_license": "", "do_not_record": false, "persons": [{"id": 229, "code": "PRREQL", "public_name": "Alyona Galyeva", "biography": "Alyona Galyeva is an organizer of PyLadies Amsterdam, co-organizer of MLOps and Crafts, Microsoft AI MVP and Principal Engineer at Thoughtworks\r\nObserve - Optimize - Learn - Repeat \r\nPassionate about encouraging others to see different perspectives and constructively break the rules.\r\nI found my joy in building, optimizing, and deploying end-to-end AI and Data Engineering Solutions.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 132, "guid": "0b7e549a-0c06-502d-ad0f-ec3ed74ca80f", "logo": "", "date": "2023-09-16T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 1", "slug": "cfp-132-production-data-to-the-model-are-you-getting-my-drift-", "url": "https://amsterdam2023.pydata.org/cfp/talk/JMNB9B/", "title": "Production Data to the Model: \u201cAre You Getting My Drift?\u201d", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "A shift is a poetic word for uncertainty. Winds shift, rivers and sands drift, and people change. Coming to the not-so-poetic world of data science, what about the data? Data comes from systems and people using them, so it is natural that data too will see the rigors of shift too. A model that was trained and tested for particular dynamics may assume the expected uncertainty in the data such as a shift in the user behavior. But what happens when the shift goes beyond expectations? How do teams detect the different types of data drift? More so, how do they tackle the detected drift? In this talk, I would gently introduce you to data drift and how the industry tackles this issue.", "description": "<i>\u201cEverything you see has its roots in the unseen world. The forms may change, yet the essence remains the same.\u201d</i>\r\n<p>When Rumi wrote this quote, machine learning was not even an idea. Therefore we can safely assume that these soothing words do not apply to the probability distribution of predictors and targets. The said distribution can change from something trivial like a change of collection metric system to something as disruptive as a pandemic.\r\nKeeping track of data drift has become an essential part of industrializing the machine-learning process. A simple mix of understanding the kind of data the model would encounter, mathematics, and a suitable detection strategy can help teams watch out for model performance decay. Additionally, it is important for data science practitioners to understand the types of drifts to devise the best detection strategy.\r\nMy talk will focus on the following:\r\nIntroduction to data drift and the cost of ignoring it\r\nTypes of data drift \r\nCommonly-used tests to detect drift in numerical and categorical data\r\nA short Python-based walkthrough of detection methods\r\nHow is drift detected for unstructured data like text?\r\nDrift happened and we caught it, now what?\r\n</p>\r\n\r\nThe intended target audience is broad since anyone who has deployed or wishes to deploy their model needs to be aware of this issue.", "recording_license": "", "do_not_record": false, "persons": [{"id": 143, "code": "WXPEB9", "public_name": "Gatha", "biography": "Hello there! I am a research scientist and also blog about AI and data privacy. Recently, I wrapped up my Ph.D. in data science. Also, I'm a dog mom and love painting watercolors.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 63, "guid": "56b64bc2-19f4-55f7-bed5-fbc4a5c50425", "logo": "", "date": "2023-09-16T12:10:00+02:00", "start": "12:10", "duration": "00:30", "room": "Room 1", "slug": "cfp-63-lets-do-the-time-warp-again-time-series-machine-learning-with-distance-functions", "url": "https://amsterdam2023.pydata.org/cfp/talk/ENQV3F/", "title": "Lets do the time warp again: time series machine learning with distance functions", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Many algorithms for machine learning from time series are based on measuring the distance or similarity between series. The most popular distance measure is dynamic time warping, which attempts to optimally realign two series to compensate for offest. There are many others though. We present an overview of the most popular time series specific distance functions and describe their speed optimised implementations in aeon, a scikit-learn compatible time series machine learning toolkit. We demonstrate their application for clustering, classification and regression on a real world case study and highlight some of the latest distance based time series machine learning tools available in aeon.", "description": "This talk introduces you to popular time series distance functions and demonstrates their usage in exploratory and predictive modelling of time series. Participants will come away with an idea of how to use the very latest research into time series distances for clustering, classification and regression using the aeon toolkit and scikit learn. The talk will be mostly practical and code based, with some algorithmic and mathematical notation.  \r\n\r\nDistances are used in all forms of time series machine learning. They can help explore collections of time series through clustering, reduce dimensionality by averaging and be used with instance based or kernel based classifiers and regressors. They are used in streaming based anomaly detection and change point detection and have been embedded within tree based ensembles for classification. \r\n\r\nThe basic problem in specifying a distance function is to quantify how dissimilar two series are. Elastic distances attempt to compensate for small mis-alignments caused by offset that would make similar series look very different to measures such as Euclidean distance or correlation. There have been many different algorithms that combine forms of time warping (stretching the indexes to realign series) and editing (removing time points from one of the series to improve alignment). In the first part of the talk we will provide a high level overview and visualisation of the differences between these algorithms before describing the aeon toolkit, which contains the most comprehensive and fastest library of elastic distances that we are aware of. aeon distances can be used directly with sklearn distance based algorithms and with the many time series specific algorithms for classification, clustering and regression available in aeon. In the the middle section of the tutorial we will use a real world industrial dataset to demonstrate use cases in clustering, classification and regression. We will end with some pointers to the very latest research into using distance functions. We will require attendees to have a basic knowledge of scikit-learn and standard machine learning algorithms. \r\n\r\nThis should appeal to anyone interested in machine learning from time series. It will focus on practical application and algorithm comprehension rather than maths, and will identify the very latest research into algorithm development to suggest further reading. We will provide easy to follow notbooks prior to the talk and all examples will be freely available.", "recording_license": "", "do_not_record": false, "persons": [{"id": 78, "code": "G8AACF", "public_name": "Tony Bagnall", "biography": "Tony is a Professor of Computer Science at the University of East Anglia, where he leads the time series machine learning group. His primary research interest is in time series machine learning, with a historic focus on classification, but more recently looking at clustering and regression. He has a side interest in ensemble design.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 2": [{"id": 76, "guid": "86f6e0f4-9664-5e9c-af9b-addbb9375abf", "logo": "/media/cfp/submissions/GPSJNS/elephants_RzUTNfi.jpeg", "date": "2023-09-16T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 2", "slug": "cfp-76-our-journey-using-data-and-ai-to-help-monitor-wildlife-in-parks-in-africa", "url": "https://amsterdam2023.pydata.org/cfp/talk/GPSJNS/", "title": "Our journey using data and AI to help monitor wildlife in parks in Africa", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Exploration of the intersection between data, AI, and environmental conservation. In this talk, we will share our experiences and practical insights during our journey trying to develop a system using Python, camera traps and data-driven techniques to help detect poachers in Africa.", "description": "In this storytelling and informative talk, we will delve into our experience of data and AI to monitor wildlife in parks in Africa. Our objective is to provide attendees with a comprehensive understanding of the applications, challenges, and opportunities of leveraging data-driven techniques in environmental conservation.\r\n\r\nAudience : individuals interested in leveraging data for positive impact. \r\n\r\nThe talk is accessible to a non-technical audience in its story-telling part, but also contains technical parts and details, as well as a live demonstration of the developed and open-sourced solution. Knowledge of Python and cloud infrastructures may be useful. \r\nTechnologies explored : Python, Node-RED, Streamlit, Google Cloud Platform, Google Vision API, Zamba, Earth Rangers.", "recording_license": "", "do_not_record": false, "persons": [{"id": 96, "code": "XCTGVK", "public_name": "Ma\u00ebl Deschamps", "biography": "Manager Machine Learning Engineer, I lead the MLOps Expertise in a team of 20+ Data Engineers & Data Scientist. During my time between Shanghai and Amsterdam I explored 15+ project for 10+ clients working in various industries.\r\n\r\nI find great joy in making both my teams and clients happy. I believe in management through empathy and transparency and I'm passionate about Data Sustainability and all its related technical challenges.\r\nFeel free to reach-out to discuss any of those topics.", "answers": []}, {"id": 97, "code": "NCYNNT", "public_name": "Simone Gayed Said", "biography": "Hello Hello! \ud83c\udf1f I'm Simone, I work as a Machine Learning engineer, and I'm all about using my skills to make a positive impact on the World! \ud83d\ude80\u2728", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 124, "guid": "0c8b6f48-94a7-579a-9920-00350de3f2e0", "logo": "", "date": "2023-09-16T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 2", "slug": "cfp-124-standby-detection-with-a-human-in-the-loop", "url": "https://amsterdam2023.pydata.org/cfp/talk/TDHVEY/", "title": "Standby detection with a human in the loop", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In the Netherlands a large share of energy is used by industry. By measuring the energy usage of individual machines in real time it is possible to pinpoint when machines are operating inefficiently and help factories take measures to reduce energy waste. It turns out that in most factories, the biggest source of energy waste comes from idling machines. To be able to give valuable insights and provide relevant alerts to our customers, we set up a machine learning system for standby detection with a \u201chuman in the loop\u201d. In this talk we will go over the considerations that go into setting up a machine learning system with a human in the loop and showcase our approach to the problem. No background knowledge is required for this talk.", "description": "In the Netherlands a large share of energy is used by industry (>40% compared to only 14% used by households*). Eliminating energy waste in this sector is a big step forward towards a greener future. Therefore, Sensorfact made it its mission to eliminate all industrial energy waste. By measuring the energy usage (electricity or gas) of individual machines in real time it is possible to pinpoint when machines are operating inefficiently and help factories take measures to reduce energy waste.\r\n \r\nIt turns out that in most factories, the biggest source of energy waste comes from forgetting to turn off machines when they are not used. Flagging idling machines based on their electricity usage may seem like a trivial problem at first, however the large variety in machines and production processes makes this a lot harder than you would expect. To be able to give valuable insights on idling machines and provide relevant alerts to our customers, we set up a machine learning system with a \u201chuman in the loop\u201d. \r\n\r\nIn many settings it is perfectly fine to embed a machine learning model in a process without any human interference. However, there are cases where it is better to keep a human in the loop. The most obvious use cases are those where there is simply no room for error, for example in medical applications. However, also in less life threatening it can be beneficial to have a human act as gatekeeper ensuring high quality outputs. In this talk we will go over the considerations that go into setting up a machine learning system with a human in the loop and showcase our approach to the problem, using the case of standby detection. We will share learnings from our own experience and along the way give you an overview of the (open source) tools we chose to use for the different facets of the project. \r\n\r\nNo background knowledge is required for this talk. If you are looking for inspiration on how to build a machine learning system with a human in the loop or if you are curious about sustainability use cases this talk may be interesting for you.\r\n\r\n*https://www.clo.nl/indicatoren/nl0052-energieverbruik-per-sector", "recording_license": "", "do_not_record": false, "persons": [{"id": 77, "code": "FL7NSL", "public_name": "Lieke Kools", "biography": "Lieke is lead data scientist at Sensorfact, a company aiming to eliminate all industrial energy waste for SME\u2019s. In her role she focusses on the data fueled products that help their consultants to efficiently and effectively give advice to customers. Before joining Sensorfact she worked as a data science consultant at Vantage AI and completed a PhD in econometrics.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 262, "guid": "569b4008-5ff9-5ec2-8c88-6dfca3e583cd", "logo": "", "date": "2023-09-16T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 2", "slug": "cfp-262-building-true-machine-learning-mvps-avoiding-pitfalls-and-validating-the-value-chain", "url": "https://amsterdam2023.pydata.org/cfp/talk/PWJAVN/", "title": "Building True Machine Learning MVPs: Avoiding Pitfalls and Validating the Value Chain", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Learn how to build true Machine Learning Minimum Viable Products (MVPs) and avoid common pitfalls! MVPs are not just about testing performance; they allow you to validate the entire value chain, assess feasibility, and gauge desirability. In this talk, we will share practical insights and strategies from our experience of predicting customer intent for the ING mobile banking app. Discover how to rapidly iterate, leverage existing resources, and ensure your MVPs validate the right assumptions.", "description": "The talk aims to equip attendees with practical knowledge and strategies to build true machine learning MVPs and avoid common pitfalls. It will inspire data science teams to approach MVP development as a holistic process that validates the value chain and aligns with business objectives, showcasing how to hack the system with existing resources and how to find the complete list of assumptions to validate.\r\n\r\nThe talk will cover the following key points:\r\n1. Understanding True MVPs: (5 minutes)\r\n- Explore the concept of true machine learning MVPs beyond model testing.\r\n- Topics covered: validating the entire value chain, assessing feasibility and desirability.\r\n2. Avoiding Pitfalls: (10 minutes)\r\n- Discuss common pitfalls and misconceptions in building MVPs.\r\n- Provide some examples of how these pitfalls invalidated projects in the past (e.g. discovering sleeping dogs in mortgages)\r\n3. Lessons from Predicting Customer Intent: (10 minutes)\r\n- Share insights from our experience of predicting customer intent for the ING mobile banking app.\r\n- Highlight how we leveraged existing resources by reusing front-end components and utilizing a simple SQL query to drive rapid iteration.", "recording_license": "", "do_not_record": false, "persons": [{"id": 254, "code": "VSNDXU", "public_name": "Azamat Omuraliev", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 86, "guid": "ffdd7835-3743-5f4b-99ca-ebe6cfbb21ee", "logo": "", "date": "2023-09-16T12:10:00+02:00", "start": "12:10", "duration": "00:30", "room": "Room 2", "slug": "cfp-86-bayesian-ranking-for-tennis-players-in-pymc", "url": "https://amsterdam2023.pydata.org/cfp/talk/7RENTH/", "title": "Bayesian ranking for tennis players in PyMC", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In this talk, we will explore the Bayesian Bradley Terry model implemented in PyMC. We will focus on its application for ranking tennis players, demonstrating how this probabilistic approach can provide an accurate and robust rankings, arguably better than the ATP ranking itself and the Elo rating system.\r\n\r\nBy leveraging the power of Bayesian statistics, we can incorporate prior knowledge, handle uncertainty, and make better inferences about player abilities. Join us to learn how to implement the Bayesian Bradley Terry model in PyMC and discover its advantages for ranking tennis players.", "description": "The Bradley Terry model is a powerful model to predict the outcome of a paired comparison, as a by-product we will be able to rank players based on their hidden (latent) ability scores. Traditionally, rankings have been based on simple win-loss records, which may not capture the true abilities of players due to variations in competition quality and sample size. By adopting a Bayesian framework, we can overcome these limitations and obtain more reliable rankings.\r\n\r\nIn this talk, we will introduce the Bayesian Bradley Terry model and its underlying principles. We will explore how to encode the model in Python using the PyMC library. We will walk through the step-by-step implementation, highlighting key considerations and practical tips.\r\n\r\nTo illustrate the model's effectiveness, we will showcase its application to ranking tennis players, and compare it with both the official ATP ranking and the ELO ranking system. Tennis provides an ideal domain for this analysis, as it involves head-to-head matches between players, allowing us to directly compare their abilities. By applying the Bayesian Bradley Terry model to historical tennis match data, we can generate rankings that better reflect players' true skills, accounting for factors such as opponent strength and match surface.\r\n\r\nThroughout the talk, we will emphasize a hands-on approach, providing code examples and demonstrations. Attendees will gain a solid understanding of the model, learn how to implement it using PyMC, a practical application, possible extensions and maybe a few PyMC tricks along the way.\r\n\r\n### Outline\r\n\r\n* What's wrong with current tennis ranking.\r\n* Introduction to the Bayesian Bradley Terry model.\r\n* Implementation of the model in PyMC.\r\n* Application to ranking tennis players by latent ability score.\r\n* Comparison with ATP ranking and ELO rating system.\r\n* Possible extensions and other applications.\r\n\r\n### Prerequisites\r\n\r\nBasic knowledge of Python, PyMC and probability concepts will be helpful.", "recording_license": "", "do_not_record": false, "persons": [{"id": 81, "code": "LWAMGF", "public_name": "Francesco Bruzzesi", "biography": "Data scientist at HelloFresh with a background in pure mathematics.\r\nOpen source enthusiast and ML practitioner.", "answers": []}], "links": [], "attachments": [], "answers": []}], "Room 3": [{"id": 269, "guid": "e0485fc1-fcb3-535a-98fd-85efd758a50e", "logo": "", "date": "2023-09-16T09:00:00+02:00", "start": "09:00", "duration": "00:50", "room": "Room 3", "slug": "cfp-269-keynote-natural-intelligence-is-all-you-need-tm-", "url": "https://amsterdam2023.pydata.org/cfp/talk/C778PM/", "title": "Keynote \"Natural Intelligence is All You Need [tm]\"", "subtitle": "", "track": null, "type": "Keynote", "language": "en", "abstract": "In this talk I will try to show you what might happen if you allow yourself the creative **freedom** to rethink and reinvent common practices once in a while. As it turns out, in order to do that, natural intelligence is all you need. And we may start needing a lot of it in the near future", "description": "I\u2019ve met a lot of authoritative people in my field who pass out advise that sounds like this:\r\n\r\nWorking on recommenders? Collect all the data! Sessions!\r\nWorking on text classification? That\u2019s a solved problem! Bert!\r\nWorking with embeddings? There\u2019s a library for that already!\r\nWorking on tabular data? XGBoost for the win! GridSearch!\r\n\r\nIn short: \u201cthis is how you do data science, don\u2019t go and reinvent the wheel\u201d.\r\n\r\nIf you spend 5 minutes thinking about \u201cthe invention of the wheel\u201d though, then you may start to rethink. After all: the wheels on a bike are different from the wheels on an airplane, just like the wheels of a tractor. And for Pete\u2019s sake: that\u2019s a good thing! If we hadn\u2019t reinvented those wheels, we\u2019re be stuck with wooden horse carts.\r\n\r\nSo is it really a bad thing if we try to rethink our tools? What if, as a field, we\u2019re not moving because we\u2019re too afraid of reinventing the wheel?\r\n\r\nIn this talk I will try to show you what might happen if you allow yourself the creative **freedom** to rethink and reinvent common practices once in a while. As it turns out, in order to do that, natural intelligence is all you need. And we may start needing a lot of it in the near future", "recording_license": "", "do_not_record": false, "persons": [{"id": 281, "code": "NNGV77", "public_name": "Vincent Warmerdam", "biography": "Vincent D. Warmerdam is a software developer and senior data person. He\u2019s currently works over at Explosion to work on data quality tools for developers. He\u2019s also known for creating calmcode.io as well as a bunch of open source projects. You can check out his blog over at koaning.io to learn more about those.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 180, "guid": "ce9ef2b8-e1bc-59de-8de7-8d5809253967", "logo": "", "date": "2023-09-16T10:00:00+02:00", "start": "10:00", "duration": "00:30", "room": "Room 3", "slug": "cfp-180-transfer-learning-in-boosting-models", "url": "https://amsterdam2023.pydata.org/cfp/talk/SMDLWH/", "title": "Transfer Learning in Boosting Models", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Did you know that you could do transfer learning on boosted forests too? Even in current days, we face business cases where the modelling sample is very low. This brings an uncertainty to the modelling results and in some cases no ability to model at all. To counter it, we investigated the ability to use transfer learning approaches on boosting models. In this talk, we would like to show the methods used and results from a real case example applied to the credit risk domain.", "description": "Transfer learning (TL), a form of machine learning, involves leveraging knowledge acquired while addressing one task and applying it to a related task. While TL is mainly associated with deep learning tasks, it is also applicable to boosting algorithms which are commonly used in advanced credit risk modelling.   \r\n\r\nDuring the talk, we present a real use-case involving building a probability of default (PD) model for a customer segment with small data history within the bank. There can be several ways to benefit from data coming from other customer segments with already rich data available within the bank.   \r\n\r\nSimple approaches would be:  \r\n- Fit a model on only rich data & just apply to the limited data  \r\n- Fit a model on both data sets, but tune it on the limited data  \r\n\r\nMore complex (TL) approaches:  \r\n- Fit a model on rich data with sample weights come from resemblance analysis to calculate similarity between these two data sources.  \r\n- Use refitting with the limited data on the model trained on rich data  \r\n- Start with an initial pre-trained model while modelling on the limited data  \r\n\r\nJoin us for an engaging session where we will share the outcomes of our experiments and lessons learned, as we address these approaches that hold relevance beyond the presented use-case, offering practical applicability for similar scenarios in your own domain.", "recording_license": "", "do_not_record": false, "persons": [{"id": 186, "code": "TGAZKP", "public_name": "Busra Cikla", "biography": "Busra is an experienced data scientist with passion for analytics at ING\u2019s Risk & Pricing Advanced Analytics Team in Amsterdam. She has designed and developed end-to-end advanced analytics solutions to a business problem in different domains during the last 5 years at ING. Currently, she is working on real-time credit risk models by using ML. Busra has a background on optimisation and operational research from her B.Sc. study and she has M.Sc. degree on Data Science.", "answers": []}, {"id": 253, "code": "AEUWKA", "public_name": "Paul Zhutovsky", "biography": null, "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 29, "guid": "3f11b211-2573-5bfb-bf12-33dfea2ab2a7", "logo": "", "date": "2023-09-16T10:50:00+02:00", "start": "10:50", "duration": "00:30", "room": "Room 3", "slug": "cfp-29-enhancing-economic-outcomes-leveraging-business-metrics-for-machine-learning-model-optimization", "url": "https://amsterdam2023.pydata.org/cfp/talk/98HBMC/", "title": "Enhancing Economic Outcomes: Leveraging Business Metrics for Machine Learning Model Optimization", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "Optimizing machine learning models using regular metrics is a common practice in the industry. However, aligning model optimization with business metrics is closely tied to the objectives of the business and is highly valued by product managers and other stakeholders. This talk delves into the process of training machine learning models based on business metrics in order to enhance economic outcomes. With a primary focus on data scientists and machine learning practitioners, this talk explores techniques, methodologies, and real-world applications that harness the power of business metrics to propel machine learning models and foster business success. We will present a specific case study that demonstrates how we utilized business metrics at Booking.com that brought significant impact on model performance on business outcomes. Specifically, we will discuss our approaches to leveraging business metrics for hyperparameter tuning and reducing model complexity, which instill greater confidence within our team when deploying improved models to production.", "description": "Description\r\nThis talk aims to equip data scientists and machine learning practitioners with the knowledge and tools to train machine learning models on business metrics effectively. We will delve into the process of hyperparameter tuning, algorithm selection, and model evaluation specifically tailored for optimizing economic outcomes. A real-world use case at Booking.com will demonstrate the transformative power of this approach.\r\n\r\nOutline\r\n- Introduction to training machine learning models on machine learning metrics versus business metrics \r\n- Overview of the significance of leveraging business metrics to improve machine learning models' performance on business metrics \r\n- Introduction to machine learning algorithms suitable for modeling business metrics to drive economic optimizations \r\n- Metrics and evaluation, and training techniques specific to assessing the business impact of machine learning models\r\n- Showcasing practical use case at Booking.com where training models on business metrics has led to significant improvements in economic outcomes\r\n\r\nCentral Focus\r\nTraining machine learning models on business metrics present a powerful methodology for optimizing economic outcomes. By incorporating relevant business data and metrics into the modeling process, data scientists and machine learning practitioners can drive substantial improvements in economic performance. This talk will provide attendees with the necessary insights and techniques to apply this approach successfully.\r\n\r\nKey Takeaways\r\n- Understanding the importance of training machine learning models on business metrics for economic optimizations\r\n- Familiarity with machine learning algorithms suitable for modeling business metrics and driving economic outcomes\r\n- Strategies for evaluating and quantifying the economic impact of machine learning models\r\nReal-world inspiration and practical insights for applying this approach to boost economic outcomes\r\n\r\nExpected Background Knowledge\r\nAttendees should have a foundation in machine learning concepts and practical experience with data science techniques, in particular, knowledge of Gradient Boosting Machine (GBM) models. Familiarity with business metrics, economic principles, and optimization objectives will be beneficial but not required.\r\n\r\nWe aim to deliver an informative and practical talk that caters to data scientists and machine learning practitioners. Attendees will gain actionable insights, methodologies, and real-world examples to effectively train machine learning models on business metrics, leading to enhanced economic outcomes.", "recording_license": "", "do_not_record": false, "persons": [{"id": 43, "code": "VWZGMB", "public_name": "Felipe Moraes", "biography": "I am a machine learning scientist at Booking.com working on personalized discounts under budget constraints. \r\nI have a PhD in Computer Science from the Delft University of Technology. During my PhD, I interned as an applied scientist at Amazon Alexa Shopping, where I worked on finding proxies for what customers find relevant when comparing products during their search shopping journey in order to empower Amazon recommendation systems. Before that I obtained a BSc and MSc in Computer Science from the Federal University of Minas Gerais, visited research labs at NYU and the University of Quebec, and worked as a software engineer intern in a news recommendation system start up.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 42, "guid": "89e8ef97-184b-5aad-9054-447f5410a089", "logo": "", "date": "2023-09-16T11:30:00+02:00", "start": "11:30", "duration": "00:30", "room": "Room 3", "slug": "cfp-42-polars-and-a-peek-in-the-expression-engine", "url": "https://amsterdam2023.pydata.org/cfp/talk/DMPVZV/", "title": "Polars and a peek in the expression engine", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "This talk we will see why the expression engine in polars is so versatile and fast.\r\nWe will look at them in the perspective of the optimizer as well as the physical engine.", "description": "Polars expressions are a DSL to a very powerful vectorized engine. They make it very easy to write parallel, efficient and readable code. \r\n\r\nThis talk we will see why the expression engine in polars is so versatile and fast.\r\nWe will look at them in the perspective of the optimizer as well as the physical engine.", "recording_license": "", "do_not_record": false, "persons": [{"id": 55, "code": "BF8VWN", "public_name": "Ritchie Vink", "biography": "Ritchie Vink is the author of the Polars query engine/ DataFrame library and the CEO/Co-Founder of Polars the company. \r\n\r\nOriginally he has a background in Civil Engineering, but he switched fields and has most work experience in Machine learning and software development. Though what truly matters in experience is what he did in his side-projects.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 141, "guid": "73f28a4c-f282-5739-9cc5-d517ef4870d8", "logo": "/media/cfp/submissions/YUCS78/banner_amsterdam_intelligence_pDzZOBL.png", "date": "2023-09-16T12:10:00+02:00", "start": "12:10", "duration": "00:30", "room": "Room 3", "slug": "cfp-141-using-ai-to-make-amsterdam-greener-safer-and-more-accessible", "url": "https://amsterdam2023.pydata.org/cfp/talk/YUCS78/", "title": "Using AI to make Amsterdam greener, safer and more accessible", "subtitle": "", "track": null, "type": "Talk", "language": "en", "abstract": "In this talk, we would like to introduce you to the urban challenges that the City of Amsterdam is trying to solve using AI. We will walk you through the technical details behind one of our projects and invite you to join us in the ethical development of cool AI applications for social good.", "description": "The City of Amsterdam has the mission of promoting the development of artificial intelligence to improve the lives of Amsterdam\u2019s residents. We conduct cutting-edge research into the analysis of text, images, and point cloud data, all with the aim of solving the urban challenges of our generation and the ones to come. \r\n\r\nRecently, we\u2019ve been working on making our city more inclusive by mapping accessibility infrastructure in the public space. We\u2019ve been also working on making the city safer by localizing all street lights and automatically extracting some of their characteristics. Finally, our analysis of trees and greenery in the city can help increase the city's biodiversity and also help us reach our climate goals. \r\n\r\nWorking in the public sector means that technology itself is only a part of our job. On a daily basis, we also need to ensure that all development is done according to our city\u2019s values \u2013 for example, that applications benefit everyone, that we are open and transparent, and that we give citizens a say in shaping their (digital) city. This means (at the very least) that open-source development and the publication of methodology, data, and insights for all of our algorithms are an inseparable part of work. \r\n\r\nIn this talk, we would like to introduce you to the challenges that we face, walk you through the technical details behind one of our projects, and share the related open-source materials that can be reused by the PyData community. Finally, we hope to inspire you to join us in the ethical development of cool AI applications for social good.", "recording_license": "", "do_not_record": false, "persons": [{"id": 99, "code": "ALS3JC", "public_name": "Iva Gornishka", "biography": "Iva is a data scientist at the City of Amsterdam, part of the dedicated Urban Innovation and R&D Team which aims to improve the livability of Amsterdam by bringing AI research to the city. As part of the team\u2019s efforts to nourish the municipality's close collaboration with academia, Iva supervises MSc students conducting their thesis research on urban challenges such as managing crowdedness, detecting issues in the public space, or battling poverty.", "answers": []}, {"id": 151, "code": "XFBKUP", "public_name": "Shayla Jansen", "biography": "Data scientist at Gemeente Amsterdam", "answers": []}], "links": [], "attachments": [], "answers": []}], "Tutorial Room": [{"id": 112, "guid": "a9cfdb94-6920-5b26-b93c-f9511d7aec1f", "logo": "", "date": "2023-09-16T10:00:00+02:00", "start": "10:00", "duration": "01:20", "room": "Tutorial Room", "slug": "cfp-112-generating-data-frames-for-your-test-using-pandas-stratgies-in-hypothesis", "url": "https://amsterdam2023.pydata.org/cfp/talk/CFUCUV/", "title": "Generating Data Frames for your test - using Pandas stratgies in Hypothesis", "subtitle": "", "track": null, "type": "Tutorial__", "language": "en", "abstract": "Do you test your data pipeline? Do you use Hypothesis? In this workshop, we will use Hypothesis - a property-based testing framework to generate Pandas DataFrame for your tests, without involving any real data.", "description": "In this short 90 mins workshop, we will first go through the basics of hypothesis and what is property-based testing. After that, we will introduce the strategies for Pandas objects - available via the extras in Hypothesis. We will have a glimpse of what the strategies are doing to generate the testing object, including Pandas Series and DataFrames. In the end, we will apply what we learn in real testing applications - testing a data pipeline that involves DataFrames.\r\n\r\n## Outline\r\n- Introduction of Property-based testing (15 mins)\r\n- Introduction and basic use of Hypothesis exercises (30 mins)\r\n- Deep dive into Pandas strategies (20 mins)\r\n- Do it yourself - apply property-based testing to data pipelines (20 mins)\r\n- Conclusion (5 mins)\r\n\r\n## Prerequisits\r\nNo prior knowledge of property-based testing or hypothesis is required. However, we assume the attendee has experience using Pandas and has a basic understanding of Pandas objects. Knowledge about Numpy array and typing would also be beneficial in understanding the Pandas Strategies.\r\n\r\n## Goal\r\nWe hope the attendee will learn about property-based testing and see how it can benefit their work involved data - especially those that use Pandas. After the workshop, attendees should be able to understand how the Pandas strategies in Hypothesis works and to use Hypotheses to test codes that involve Pandas Series or DataFrame input.", "recording_license": "", "do_not_record": false, "persons": [{"id": 127, "code": "XCJT3N", "public_name": "Cheuk Ting Ho", "biography": "Before working in Developer Relations, Cheuk has been a Data Scientist in various companies which demands high numerical and programmatical skills, especially in Python. To follow her passion for the tech community, Cheuk is now the Developer Advocate. Cheuk also contributes to multiple Open Source libraries like Hypothesis, Pandas and Django.\r\n\r\nBesides her work, Cheuk enjoys talking about Python on personal streaming platforms and podcasts. Cheuk has also been a speaker at Universities and various conferences. Besides speaking at conferences, Cheuk also organises events for developers. Conferences that Cheuk has organized include EuroPython (which she is a board member), PyData Global and Pyjamas Conf. Believing in Tech Diversity and Inclusion, Cheuk constantly organizes workshops and mentored sprints for minority groups. In 2021, Cheuk has become a Python Software Foundation fellow.", "answers": []}], "links": [], "attachments": [], "answers": []}, {"id": 70, "guid": "28ea4e75-e11b-56a7-b889-08724577cd95", "logo": "", "date": "2023-09-16T11:30:00+02:00", "start": "11:30", "duration": "01:20", "room": "Tutorial Room", "slug": "cfp-70-there-are-no-bad-labels-only-happy-accidents", "url": "https://amsterdam2023.pydata.org/cfp/talk/BTLQEF/", "title": "There are no bad labels, only happy accidents", "subtitle": "", "track": null, "type": "Tutorial__", "language": "en", "abstract": "Are you 100% sure that you can trust your labels?\r\nImagine spending a company credit card worth of compute on getting the best model statistics ever. Would that be money well spent if your dataset has some labeling issues?\r\nMore often than not, \"bad labels\" are great because they can tell you how to improve the machine learning model before even training it. But it only works only if you actually spend the time being confronted with your own dataset. In this workshop, we'll annotate our own data while we leverage techniques to find happy accidents. To solve specific problems, you don't need loads of data anymore \u2013 you just need good data.", "description": "This workshop is split up into two segments.\r\nFirst, we will dive into some data quality issues of some well-known datasets. We will have prepared some datasets along with code, tricks, and Python tools to help you understand the data quality (or the lack thereof). While doing this, we will also discuss some theories behind annotator agreement metrics and show how they might help you make decisions.\r\nOnce we have some experience with these techniques, we will annotate some data as a group, after which we will share the dataset so that the group may analyze and be confronted with their own annotations.\r\nThe goal of the workshop is to give people the ability to detect a \"data smell\". Through hands-on experimentation with data quality challenges, you'll learn how to better reason about and iterate on your own data. Data quality really matters, and confronting the labeling process yourself can help you better your machine learning pipeline and evaluation process.", "recording_license": "", "do_not_record": false, "persons": [{"id": 80, "code": "BARYAD", "public_name": "Victoria Slocum", "biography": "Victoria is a Developer Advocate at Explosion, where she supports the Natural Language Processing community around the popular open-source library spaCy, the annotation tool Prodigy and other developer tools. Besides running marathons, learning new languages, and building fun machine learning projects about music and food, she loves learning about natural language processing and ensures that the open-source community has everything they need to do the same.", "answers": []}, {"id": 88, "code": "VTBNDW", "public_name": "Ines Montani", "biography": "Ines Montani is a developer specializing in tools for AI and NLP technology. She\u2019s the co-founder and CEO of Explosion and a core developer of spaCy, a popular open-source library for Natural Language Processing in Python, and Prodigy, a modern annotation tool for creating training data for machine learning models.", "answers": []}], "links": [], "attachments": [], "answers": []}]}}]}}}