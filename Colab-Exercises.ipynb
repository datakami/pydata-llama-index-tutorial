{
  "metadata": {
    "colab": {
      "name": "pydata-llama-index-tutorial-colab.ipynb",
      "private_outputs": false,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "id": "12976e25-8fc1-48d4-9186-9d2bcea0de92",
      "metadata": {},
      "source": [
        "# Running this notebook in Google Colab\n",
        "This notebook is intended to run in Google Colab [here](https://colab.research.google.com/github/datakami/pydata-llama-index-tutorial/blob/main/Colab-Exercises.ipynb).\n",
        "\n",
        "Simply execute the code below to install the neccessary dependencies and download the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9da5883c-d4ec-43e0-bc95-835f875b6c77",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install llama-index==0.8.5.post2 sentence-transformers==2.2.2 loguru==0.7.0\n",
        "# download the data\n",
        "from urllib.request import urlretrieve\n",
        "path, _ = urlretrieve(\"https://pub.yori.cc/lid_data.zip\")\n",
        "import zipfile\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n",
        "!mv pydata-llama-index-tutorial-main/data pydata-llama-index-tutorial-main/indices ."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c913d2a2-f87f-4505-abb4-49e6b2291e52",
      "metadata": {},
      "source": [
        "# Part 1: Querying"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e084dce-bd60-43c1-a13d-cd9636ea2856",
      "metadata": {},
      "source": [
        "If you want to use the OpenAPI API during this tutorial, make a file `secret.py` with `openai_api_key = \"YOURKEYHERE\"`.\n",
        "\n",
        "How to use this notebook: \n",
        "1. Execute all cells under \"Setup\"\n",
        "2. Fill in the exercises below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8feb43be-6be1-4cd1-933f-cd3a77052e33",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdb21f09-827a-412c-8b19-c40fd14825a1",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "effd39ab-b6ba-4d69-8e8f-39f382d7712f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pprint\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# logging for lazy people :)\n",
        "from loguru import logger\n",
        "\n",
        "# we're not importing specific methods or classes so it's clear when we actually call llama_index!\n",
        "import llama_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b056809-10bc-4f4d-90bf-a9b8e8acd34e",
      "metadata": {},
      "source": [
        "### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f44daa1-a3e6-45bf-bc6e-8c84fad646b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.remove()\n",
        "logger.add(sys.stdout, format=\"{time} - {level} - {message}\", level=\"DEBUG\")\n",
        "logger.add(\"tutorial_part_1.log\", level=\"DEBUG\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee221890-7faa-4b1a-b593-ffe15d5976dc",
      "metadata": {},
      "source": [
        "### Tell the notebook where files are stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e2e8b1-5b94-4dcf-b109-9e8351b087b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path(\"data/pydata/schedule.json\")\n",
        "INDEX_PATH = Path(\"indices/pydata_schedule_index/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4f10b1-759c-459b-bece-1495c099cf62",
      "metadata": {},
      "source": [
        "### Tell `llama-index` to use a local embeddings model for retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3420c723-b6f0-4c1f-8a5f-9da6b875747b",
      "metadata": {},
      "source": [
        "More information about this embeddings model: https://www.sbert.net/docs/pretrained_models.html#model-overview\n",
        "\n",
        "Note that all-minilm-l6-v2 has a maximum size of 256 tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4b220f-e86c-48e6-a069-ec4d84a2b119",
      "metadata": {},
      "outputs": [],
      "source": [
        "embed_model = \"local:sentence-transformers/all-minilm-l6-v2\"\n",
        "llm = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85531cae-9ec3-47f3-b4c1-e9df4cea39f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "service_context = llama_index.ServiceContext.from_defaults(\n",
        "  embed_model=embed_model, chunk_size=256, llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b317df6-0c8c-4ec8-beb9-ce932bc34a50",
      "metadata": {},
      "source": [
        "### Load a vector index with the PyData Amsterdam 2023 schedule"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81545f8f-f540-4b5a-bc39-eac70da0771a",
      "metadata": {},
      "source": [
        "Load the index from file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8bc3e5-6bc7-4970-9a1f-c722ba931956",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(INDEX_PATH):\n",
        "    logger.error(\"Index file for part 1 does not exist on disk. :(\")\n",
        "else:\n",
        "    try:                                                                             \n",
        "        storage_context = llama_index.StorageContext.from_defaults(persist_dir=INDEX_PATH)\n",
        "        index = llama_index.load_index_from_storage(storage_context, service_context=service_context)\n",
        "        logger.info(\"Loaded index from local storage\")                               \n",
        "    except Exception as e:                                                           \n",
        "        logger.error(e) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cede9a40-f6e1-42f3-92bf-4519bfad87ef",
      "metadata": {},
      "source": [
        "## Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e2b73e6",
      "metadata": {},
      "source": [
        "### Create a retriever from the vector index `index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99828da",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08a3b1d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "83ba90ab",
      "metadata": {},
      "source": [
        "### Retrieve chunks that mention llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49dc5a88",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a2ba35",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "18ae7223",
      "metadata": {},
      "source": [
        "### Retrieve chunks related to causal machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9095ac6f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fdbaf04",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6bfb44ff",
      "metadata": {},
      "source": [
        "### Print the talk title and speaker for results related to causal machine learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a26425",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26fa7326",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c955a628",
      "metadata": {},
      "source": [
        "### Create a new retriever that retrieves more than 2 results. Hint: [llama-index Retriever documentation](https://gpt-index.readthedocs.io/en/v0.8.5.post2/api_reference/query/retrievers/vector_store.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62558f30",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adff8d44",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "43a015c6",
      "metadata": {},
      "source": [
        "### Find all talks about causal inference at PyData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee40adf3",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "731f0d54",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f81ee400-d0c5-4ad2-b68e-09c84ce4044c",
      "metadata": {},
      "source": [
        "## Querying the vector index with an external LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "601ced37-8de0-4d5e-8abb-6fae18bf1803",
      "metadata": {},
      "source": [
        "### Set OpenAI API key (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62f5b922-be03-435f-b581-053dfb47e5d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "from secret import openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "883fc70c-f18f-412c-bae5-3ac06a090a92",
      "metadata": {},
      "source": [
        "### Use OpenAI's gpt-3.5-turbo for querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4d6ce8a-85d1-4d29-a182-a749782d14c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = llama_index.llms.OpenAI(model=\"gpt-3.5-turbo\", api_key=openai_api_key)\n",
        "service_context = llama_index.ServiceContext.from_defaults(\n",
        "  embed_model=embed_model, chunk_size=256, llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54c91e61-7b94-4a1c-a68b-b22553e8b78d",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(INDEX_PATH):\n",
        "    logger.error(\"Index file for part 1 does not exist on disk. :(\")\n",
        "else:\n",
        "    try:                                                                             \n",
        "        storage_context = llama_index.StorageContext.from_defaults(persist_dir=INDEX_PATH)\n",
        "        index = llama_index.load_index_from_storage(storage_context, service_context=service_context)\n",
        "        logger.info(\"Loaded index from local storage\")                               \n",
        "    except Exception as e:                                                           \n",
        "        logger.error(e) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce43eb07",
      "metadata": {},
      "source": [
        "### Create a query engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302d3724",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec4d28c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "35bac008",
      "metadata": {},
      "source": [
        "### Find talks that might be interesting for startup founders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2cdad4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508751e0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c913d2a2-f87f-4505-abb4-49e6b2291e52",
      "metadata": {},
      "source": [
        "# Part 2: Building a custom vector index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47bccc4d-52f3-4610-afae-1b08278dad37",
      "metadata": {},
      "source": [
        "How to use this notebook: \n",
        "1. Execute all cells under \"Setup\"\n",
        "2. Fill in the exercises below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e03ae8f4-83b1-49a8-bf1e-19180366a102",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "038506f9-dcca-400c-b10b-5e7e612b1792",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "effd39ab-b6ba-4d69-8e8f-39f382d7712f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pprint\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from loguru import logger\n",
        "import llama_index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bd8c85-03d8-4894-8dfe-b419d4f6b6f2",
      "metadata": {},
      "source": [
        "### Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f44daa1-a3e6-45bf-bc6e-8c84fad646b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.remove()\n",
        "logger.add(sys.stdout, format=\"{time} - {level} - {message}\", level=\"DEBUG\")\n",
        "logger.add(\"tutorial_part_1.log\", level=\"DEBUG\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e2e8b1-5b94-4dcf-b109-9e8351b087b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = Path(\"data/julia_evans/blogposts.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da94c113-deb9-49fc-a072-3f82f82afadd",
      "metadata": {},
      "source": [
        "### Load Julia Evans blogpost data from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5876b6c-0373-43d4-8f28-26b40dbf5f2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(DATA_PATH, 'r') as infile:\n",
        "    blogposts = json.loads(infile.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c02640e6-afcf-4eb6-a5e7-e89cf7914cd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info(f\"Loaded {len(blogposts)} blogposts from file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db2b0d29-ce87-454f-b7b8-e6ddd3a52c87",
      "metadata": {},
      "outputs": [],
      "source": [
        "for idx, post in enumerate(blogposts):\n",
        "    print(f\"{idx+1}: {post['title']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "867fe918-339e-4de3-a614-f73a44f4b949",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Example blogpost:\")\n",
        "pprint.pprint(blogposts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b4f10b1-759c-459b-bece-1495c099cf62",
      "metadata": {},
      "source": [
        "### Create a service context\n",
        "- No OpenAI API calls\n",
        "- No large local LLM\n",
        "- Just use the smallest sentence-transformers embeddings model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0bfd191-3038-4ad7-a073-58b93e94f8d1",
      "metadata": {},
      "source": [
        "- all-minilm-l6-v2 has a maximum size of 256 tokens\n",
        "- source: https://www.sbert.net/docs/pretrained_models.html#model-overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85531cae-9ec3-47f3-b4c1-e9df4cea39f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "service_context = llama_index.ServiceContext.from_defaults(\n",
        "  embed_model=\"local:sentence-transformers/all-minilm-l6-v2\", chunk_size=256, llm=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb5492d-e290-461a-a3f4-55f23818fee1",
      "metadata": {},
      "source": [
        "### Create documents from the blogposts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a03e2bf3-5d46-40d1-9ba5-c6d8dda9d0c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = [llama_index.Document(text=blogpost['text']) for blogpost in blogposts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e829de61-44ef-4701-b01d-e24bb34b6d78",
      "metadata": {},
      "outputs": [],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91772358-47dc-4e6a-861a-aa9e295805ca",
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Example document:\")\n",
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8bd061-8ff4-4dd2-922c-117365fd8bdf",
      "metadata": {},
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46baa1a3",
      "metadata": {},
      "source": [
        "### Create a vector index from `documents` (this could take a minute because we're processing lots of text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de0ab9f4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fbe9a8f",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "34136e6d",
      "metadata": {},
      "source": [
        "### Retrieve blogposts about DNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bd7378",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf14d573",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a12ec224",
      "metadata": {},
      "source": [
        "### It's really hard to figure out from which blogposts these results are! Create a set of Documents that has the blogpost title as the id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e92e46a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63733166",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "661de79c",
      "metadata": {},
      "source": [
        "### Build a vector index from these new documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce48e60",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e0cf75",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f52bd2bf",
      "metadata": {},
      "source": [
        "### Retrieve blogposts about DNS using the new index. This time, use the id of the source node to check from which blogpost they originate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a96e6944",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f25b67",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "477af697",
      "metadata": {},
      "source": [
        "### Store your index to disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2691f6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bceedfdf",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b79bf8b",
      "metadata": {},
      "source": [
        "### Load your index from disk in a new index variable. Hint: you need two ingredients: a storage context and a service context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8e8363",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd0a2ad",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8be33768",
      "metadata": {},
      "source": [
        "### Expand the documents in your index with metadata such as title, original URL, author, and update time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7866b337",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4de861",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a1f5fb02",
      "metadata": {},
      "source": [
        "### Create an index from these new documents. Retrieve 20 search results about Nix (a package manager)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4e8457",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a60b8dd",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "daedcd38",
      "metadata": {},
      "source": [
        "### For all 20 chunks, print their score, url and the date the blogpost was published."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c66c3b1",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e040ae",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5
}